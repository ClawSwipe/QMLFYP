{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52CR7KmybQYr",
        "outputId": "09538817-2de3-4c59-f77e-c70f0c188215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.10/dist-packages (0.38.0)\n",
            "Requirement already satisfied: pennylane-lightning in /usr/local/lib/python3.10/dist-packages (0.38.0)\n",
            "Requirement already satisfied: cotengra in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
            "Requirement already satisfied: quimb in /usr/local/lib/python3.10/dist-packages (1.8.4)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.3)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.15.1)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.7.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: autoray>=0.6.11 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.6.12)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pennylane) (24.1)\n",
            "Requirement already satisfied: pennylane-lightning-gpu in /usr/local/lib/python3.10/dist-packages (from pennylane-lightning[gpu]) (0.38.0)\n",
            "Requirement already satisfied: cytoolz>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from quimb) (1.0.0)\n",
            "Requirement already satisfied: numba>=0.39 in /usr/local/lib/python3.10/dist-packages (from quimb) (0.60.0)\n",
            "Requirement already satisfied: psutil>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from quimb) (5.9.5)\n",
            "Requirement already satisfied: tqdm>=4 in /usr/local/lib/python3.10/dist-packages (from quimb) (4.66.5)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from cytoolz>=0.8.0->quimb) (0.12.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.39->quimb) (0.43.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2024.8.30)\n",
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
            "Requirement already satisfied: jax[cuda12_pip] in /usr/local/lib/python3.10/dist-packages (0.4.34)\n",
            "Requirement already satisfied: jaxlib<=0.4.34,>=0.4.34 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]) (0.4.34)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]) (1.13.1)\n",
            "Requirement already satisfied: jax-cuda12-plugin<=0.4.34,>=0.4.34 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda12-pip\"->jax[cuda12_pip]) (0.4.34)\n",
            "Requirement already satisfied: jax-cuda12-pjrt==0.4.34 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin<=0.4.34,>=0.4.34->jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda12-pip\"->jax[cuda12_pip]) (0.4.34)\n",
            "Requirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda12-pip\"->jax[cuda12_pip]) (12.6.3.3)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12>=12.1.105 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda12-pip\"->jax[cuda12_pip]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cuda-nvcc-cu12>=12.1.105 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda12-pip\"->jax[cuda12_pip]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda12-pip\"->jax[cuda12_pip]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12<10.0,>=9.1 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda12-pip\"->jax[cuda12_pip]) (9.4.0.58)\n",
            "Requirement already satisfied: nvidia-cufft-cu12>=11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda12-pip\"->jax[cuda12_pip]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12>=11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda12-pip\"->jax[cuda12_pip]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12>=12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda12-pip\"->jax[cuda12_pip]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12>=2.18.1 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda12-pip\"->jax[cuda12_pip]) (2.23.4)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12>=12.1.105 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda12-pip\"->jax[cuda12_pip]) (12.6.77)\n"
          ]
        }
      ],
      "source": [
        "# Install packages\n",
        "!pip install pennylane pennylane-lightning pennylane-lightning[gpu] cotengra quimb --upgrade\n",
        "!pip install -U \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "# !pip install --upgrade \"jax[cuda11_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "#np.set_printoptions(threshold=sys.maxsize)\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "import seaborn as sns\n",
        "import jax\n",
        "import time\n",
        "\n",
        "import functools\n",
        "\n",
        "from typing import List, Union, Tuple, Dict, Optional, Any\n",
        "from typing import Callable\n",
        "\n",
        "jax.config.update(\"jax_enable_x64\", True)\n",
        "#jax.config.update(\"jax_debug_nans\", True)\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import optax  # optimization using jax\n",
        "\n",
        "import torch  # https://pytorch.org\n",
        "import torchvision  # https://pytorch.org\n",
        "#torch.set_printoptions(profile=\"full\")\n",
        "import pennylane as qml\n",
        "import pennylane.numpy as pnp\n",
        "\n",
        "import os, cv2, itertools # cv2 -- OpenCV\n",
        "import shutil\n",
        "import zipfile\n",
        "%matplotlib inline\n",
        "\n",
        "from jax.lib import xla_bridge\n",
        "\n",
        "def set_jax_platform():\n",
        "    # Check if TPU is available\n",
        "    try:\n",
        "        tpu_backend = xla_bridge.get_backend('tpu')\n",
        "        if tpu_backend and tpu_backend.device_count() > 0:\n",
        "            # Set platform to TPU\n",
        "            jax.config.update('jax_platform_name', 'tpu')\n",
        "            print(\"Set platform to TPU\")\n",
        "            return\n",
        "    except RuntimeError:\n",
        "        pass  # No TPU found, move on to check for GPU\n",
        "\n",
        "    # Check if GPU is available\n",
        "    try:\n",
        "      gpu_backend = xla_bridge.get_backend('gpu')\n",
        "      if gpu_backend and gpu_backend.device_count() > 0:\n",
        "          # Set platform to CUDA (GPU)\n",
        "          jax.config.update('jax_platform_name', 'gpu')\n",
        "          print(\"Set platform to GPU\")\n",
        "    except RuntimeError:\n",
        "          # Set platform to CPU\n",
        "          jax.config.update('jax_platform_name', 'cpu')\n",
        "          print(\"Set platform to CPU\")\n",
        "\n",
        "# Call the function to set the platform\n",
        "set_jax_platform()\n",
        "\n",
        "sns.set()\n",
        "\n",
        "seed = 1701\n",
        "rng = np.random.default_rng(seed=seed)\n",
        "prng = pnp.random.default_rng(seed=seed)\n",
        "jrng_key = jax.random.PRNGKey(seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC92azd1bgkU",
        "outputId": "e1e9d9c5-ce50-4a78-a407-da4c1c759522"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-b00b07bf67a6>:40: DeprecationWarning: jax.lib.xla_bridge.get_backend is deprecated; use jax.extend.backend.get_backend.\n",
            "  tpu_backend = xla_bridge.get_backend('tpu')\n",
            "<ipython-input-4-b00b07bf67a6>:51: DeprecationWarning: jax.lib.xla_bridge.get_backend is deprecated; use jax.extend.backend.get_backend.\n",
            "  gpu_backend = xla_bridge.get_backend('gpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Set platform to GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the Dataset\n",
        "\n",
        "For the rescaled image matrix $M$, the \"Hermitian version\" of it can be calculated as:\n",
        "\n",
        "$$\n",
        "A = \\frac{M+M^T}{2}\n",
        "$$"
      ],
      "metadata": {
        "id": "LCo8fdobbiTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Pad(2),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Lambda(lambda x: torch.squeeze(x)),\n",
        "    #torchvision.transforms.Lambda(lambda x: x / torch.trace(x)),\n",
        "    torchvision.transforms.Lambda(lambda x: (x+torch.transpose(x, 0, 1))/2)\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    \"MNIST\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=preprocess,\n",
        ")\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    \"MNIST\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=preprocess,\n",
        ")\n",
        "dummy_trainloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=64, shuffle=True\n",
        ")\n",
        "dummy_testloader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=64, shuffle=True\n",
        ")\n",
        "\n",
        "dummy_x, dummy_y = next(iter(dummy_trainloader))\n",
        "dummy_x = dummy_x.numpy()\n",
        "dummy_y = dummy_y.numpy()\n",
        "print(dummy_x.shape)  # 64x32x32\n",
        "print(dummy_y.shape)  # 64\n",
        "print(dummy_y)\n",
        "print(dummy_x[0,16])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlSUCStebkoA",
        "outputId": "10281b9b-9e5e-4d35-9ab1-95137b377c9d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 32, 32)\n",
            "(64,)\n",
            "[0 5 9 6 2 9 2 2 7 8 1 5 1 8 2 9 1 6 6 9 0 6 9 5 6 9 8 9 4 2 6 8 5 8 3 9 3\n",
            " 2 5 9 8 7 9 4 3 8 3 8 6 4 7 2 3 9 2 0 1 0 6 7 7 6 4 9]\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.13725491 0.5254902  0.99607843 0.99607843 0.99607843\n",
            " 0.6333333  0.00196078 0.         0.         0.         0.\n",
            " 0.         0.         0.22745098 0.49803922 0.6117647  0.9196079\n",
            " 0.5647059  0.49803922 0.         0.         0.         0.\n",
            " 0.         0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time-Evolve the Image Hermitian"
      ],
      "metadata": {
        "id": "TR5l9DZ5bubn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def img_hermitian_evolve(\n",
        "    img:jnp.ndarray,\n",
        "    t:float\n",
        ")->jnp.ndarray:\n",
        "  assert img.shape[-1]==32 and img.shape[-2] == 32, f\"The shape of the image must be 32 by 32, got {img.shape[-2]} by {img.shape[-1]}\"\n",
        "  return jax.scipy.linalg.expm(img*( -0.5j*t))\n",
        "\n",
        "print(\n",
        "    img_hermitian_evolve(\n",
        "        dummy_x[0],\n",
        "        10\n",
        "        )[16]\n",
        "    )\n",
        "\n",
        "\n",
        "print(\n",
        "    jnp.einsum(\n",
        "        \"ij,jk->ik\",\n",
        "        jnp.transpose(jnp.conjugate(img_hermitian_evolve(\n",
        "        dummy_x[0],\n",
        "        10\n",
        "        ))),\n",
        "        img_hermitian_evolve(\n",
        "        dummy_x[0],\n",
        "        10\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\n",
        "    jnp.einsum(\n",
        "        \"ij,jk->ik\",\n",
        "        img_hermitian_evolve(\n",
        "        dummy_x[0],\n",
        "        10\n",
        "        ),\n",
        "        jnp.transpose(jnp.conjugate(img_hermitian_evolve(\n",
        "        dummy_x[0],\n",
        "        10\n",
        "        )))\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYbF2gRNbxKF",
        "outputId": "12873c6c-7588-430e-bb1b-0bb066c4d18f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.        +0.j          0.        +0.j          0.        +0.j\n",
            "  0.        +0.j          0.        +0.j          0.        +0.j\n",
            "  0.00082034+0.11590593j  0.04222612+0.15231173j  0.0375471 -0.15866779j\n",
            "  0.02580507-0.11731668j  0.09450033-0.02282472j  0.1268137 -0.0978322j\n",
            " -0.26759338+0.05791944j -0.24705204+0.12401491j  0.14304939-0.21774071j\n",
            " -0.3786658 +0.1487148j   0.3797479 +0.14957352j -0.09449394+0.14450297j\n",
            " -0.14984648+0.10052249j -0.25428373+0.00263548j -0.1138505 +0.04622044j\n",
            " -0.22796603-0.21002199j  0.02128542+0.11869261j  0.18040164-0.1475296j\n",
            " -0.13087638-0.01179099j  0.09810758+0.0132283j   0.        +0.j\n",
            "  0.        +0.j          0.        +0.j          0.        +0.j\n",
            "  0.        +0.j          0.        +0.j        ]\n",
            "[[1.+0.j 0.+0.j 0.+0.j ... 0.+0.j 0.+0.j 0.+0.j]\n",
            " [0.+0.j 1.+0.j 0.+0.j ... 0.+0.j 0.+0.j 0.+0.j]\n",
            " [0.+0.j 0.+0.j 1.+0.j ... 0.+0.j 0.+0.j 0.+0.j]\n",
            " ...\n",
            " [0.+0.j 0.+0.j 0.+0.j ... 1.+0.j 0.+0.j 0.+0.j]\n",
            " [0.+0.j 0.+0.j 0.+0.j ... 0.+0.j 1.+0.j 0.+0.j]\n",
            " [0.+0.j 0.+0.j 0.+0.j ... 0.+0.j 0.+0.j 1.+0.j]]\n",
            "[[1.+0.j 0.+0.j 0.+0.j ... 0.+0.j 0.+0.j 0.+0.j]\n",
            " [0.+0.j 1.+0.j 0.+0.j ... 0.+0.j 0.+0.j 0.+0.j]\n",
            " [0.+0.j 0.+0.j 1.+0.j ... 0.+0.j 0.+0.j 0.+0.j]\n",
            " ...\n",
            " [0.+0.j 0.+0.j 0.+0.j ... 1.+0.j 0.+0.j 0.+0.j]\n",
            " [0.+0.j 0.+0.j 0.+0.j ... 0.+0.j 1.+0.j 0.+0.j]\n",
            " [0.+0.j 0.+0.j 0.+0.j ... 0.+0.j 0.+0.j 1.+0.j]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Utilities"
      ],
      "metadata": {
        "id": "enL2qIVtcNLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ket = {\n",
        "    '0':jnp.array([1,0]),\n",
        "    '1':jnp.array([0,1]),\n",
        "    '+':(jnp.array([1,0]) + jnp.array([0,1]))/jnp.sqrt(2),\n",
        "    '-':(jnp.array([1,0]) - jnp.array([0,1]))/jnp.sqrt(2)\n",
        "}\n",
        "\n",
        "pauli = {\n",
        "    'I':jnp.array([[1,0],[0,1]]),\n",
        "    'X':jnp.array([[0,1],[1,0]]),\n",
        "    'Y':jnp.array([[0, -1j],[1j, 0]]),\n",
        "    'Z':jnp.array([[1,0],[0,-1]])\n",
        "}\n",
        "\n",
        "def tensor_product(*args):\n",
        "  input_list = [a for a in args]\n",
        "  return functools.reduce(jnp.kron, input_list)\n",
        "\n",
        "def multi_qubit_identity(n_qubits:int)->jnp.ndarray:\n",
        "  assert n_qubits>0\n",
        "  if n_qubits == 1:\n",
        "    return pauli['I']\n",
        "  else:\n",
        "    return tensor_product(*[pauli['I'] for _ in range(n_qubits)])\n",
        "\n",
        "pauli_words_su4 = {}\n",
        "for key1 in pauli.keys():\n",
        "  for key2 in pauli.keys():\n",
        "    if not (key1==key2 and key1=='I' and key2=='I'):\n",
        "      pauli_words_su4[key1+key2] = tensor_product(pauli[key1], pauli[key2])\n",
        "\n",
        "pauli_words_su8 = {}\n",
        "for key1 in pauli.keys():\n",
        "  for key2 in pauli.keys():\n",
        "    for key3 in pauli.keys():\n",
        "      if not key1+key2+key3 == 'III':\n",
        "        pauli_words_su8[key1+key2+key3] = tensor_product(pauli[key1], pauli[key2], pauli[key3])\n",
        "\n",
        "pauli_words_su16 = {}\n",
        "for key1 in pauli.keys():\n",
        "  for key2 in pauli.keys():\n",
        "    for key3 in pauli.keys():\n",
        "      for key4 in pauli.keys():\n",
        "        if not key1+key2+key3+key4 == 'IIII':\n",
        "          pauli_words_su16[key1+key2+key3+key4] = tensor_product(\n",
        "              pauli[key1],\n",
        "              pauli[key2],\n",
        "              pauli[key3],\n",
        "              pauli[key4]\n",
        "          )\n",
        "\n",
        "pauli_words_su32 = {}\n",
        "for key1 in pauli.keys():\n",
        "  for key2 in pauli.keys():\n",
        "    for key3 in pauli.keys():\n",
        "      for key4 in pauli.keys():\n",
        "        for key5 in pauli.keys():\n",
        "          if not key1+key2+key3+key4+key5 == 'IIIII':\n",
        "            pauli_words_su32[key1+key2+key3+key4+key5] = tensor_product(\n",
        "                pauli[key1],\n",
        "                pauli[key2],\n",
        "                pauli[key3],\n",
        "                pauli[key4],\n",
        "                pauli[key5]\n",
        "            )\n",
        "\n",
        "observables_10_cls_5q = [0]*10\n",
        "for i in ['0', '1']:\n",
        "  for j in ['0', '1']:\n",
        "    for k in ['0', '1']:\n",
        "      for l in ['0', '1']:\n",
        "        idx = int(i+j+k+l, 2)\n",
        "        if idx <10:\n",
        "          basis_state = tensor_product(*[ket[i], ket[j], ket[k], ket[l]])\n",
        "          four_qubit_obs = jnp.outer(basis_state, basis_state)\n",
        "          observables_10_cls_5q[idx] = tensor_product(four_qubit_obs, multi_qubit_identity(1))\n",
        "\n",
        "observables_8_cls_5q = [0]*8\n",
        "for i in ['0', '1']:\n",
        "  for j in ['0', '1']:\n",
        "    for k in ['0', '1']:\n",
        "      for l in ['0', '1']:\n",
        "        idx = int(i+j+k+l, 2)\n",
        "        if idx <8:\n",
        "          basis_state = tensor_product(*[ket[i], ket[j], ket[k], ket[l]])\n",
        "          four_qubit_obs = jnp.outer(basis_state, basis_state)\n",
        "          observables_8_cls_5q[idx] = tensor_product(four_qubit_obs, multi_qubit_identity(1))\n"
      ],
      "metadata": {
        "id": "xVOKRfoacK60"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def su32_op(\n",
        "    params:jnp.ndarray\n",
        "):\n",
        "  generator = jnp.einsum(\"i, ijk - >jk\", params, jnp.asarray(list(pauli_words_su32.values())))\n",
        "  return jax.scipy.linalg.expm(1j*generator)\n",
        "\n",
        "test_params = jax.random.normal(shape=[4**5-1], key=jrng_key)\n",
        "\n",
        "print(\n",
        "    jnp.einsum(\n",
        "        \"ij,jk->ik\",\n",
        "        jnp.transpose(jnp.conjugate(su32_op(test_params))),\n",
        "        su32_op(test_params)\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\n",
        "    jnp.einsum(\n",
        "        \"ij,jk->ik\",\n",
        "        su32_op(test_params),\n",
        "        jnp.transpose(jnp.conjugate(su32_op(test_params)))\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfMfQrSncpW1",
        "outputId": "3f9ee22d-fbb5-4790-b6f3-ab4c024745c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.00000000e+00-2.81802478e-18j -2.08166817e-17-6.93889390e-17j\n",
            "   1.87350135e-16+4.02455846e-16j ...  6.78276879e-16-5.07189776e-16j\n",
            "  -7.11236625e-16+6.24500451e-17j -2.53269627e-16-5.55111512e-16j]\n",
            " [-2.08166817e-17+4.85722573e-17j  1.00000000e+00+1.79597214e-18j\n",
            "   3.78169718e-16-5.82867088e-16j ...  8.04911693e-16-1.17267307e-15j\n",
            "   4.85722573e-17-4.51089090e-16j -2.35922393e-16-2.22044605e-16j]\n",
            " [ 1.87350135e-16-3.95516953e-16j  3.78169718e-16+5.55111512e-16j\n",
            "   1.00000000e+00-1.01336686e-18j ...  6.38378239e-16+8.18789481e-16j\n",
            "  -2.74086309e-16-5.20417043e-16j  4.85722573e-17-4.23272528e-16j]\n",
            " ...\n",
            " [ 6.81746326e-16+5.07189776e-16j  7.91033905e-16+1.17267307e-15j\n",
            "   6.93889390e-16-8.18789481e-16j ...  1.00000000e+00-1.40196419e-18j\n",
            "  -1.75207071e-16+8.53483950e-16j  3.46944695e-16-6.38378239e-16j]\n",
            " [-7.04297731e-16-6.24500451e-17j  4.16333634e-17+4.51089090e-16j\n",
            "  -2.63677968e-16+5.20417043e-16j ... -1.75207071e-16-8.60422844e-16j\n",
            "   1.00000000e+00+4.01611805e-18j -1.38777878e-16+5.13478149e-16j]\n",
            " [-2.60208521e-16+5.55111512e-16j -2.35922393e-16+2.22044605e-16j\n",
            "   6.72205347e-17+4.23272528e-16j ...  3.46944695e-16+6.34908792e-16j\n",
            "  -1.38777878e-16-4.99600361e-16j  1.00000000e+00-6.72126142e-18j]]\n",
            "[[ 1.00000000e+00-6.11733426e-18j -2.77555756e-16+1.28369537e-16j\n",
            "   4.89192020e-16+5.20417043e-16j ...  6.17561557e-16+8.32667268e-17j\n",
            "  -7.45931095e-16+4.44089210e-16j  2.15105711e-16+3.03576608e-16j]\n",
            " [-2.77555756e-16-1.28369537e-16j  1.00000000e+00+2.93457884e-18j\n",
            "  -4.16333634e-17-4.02455846e-16j ...  2.18575158e-16-7.97972799e-16j\n",
            "  -6.31439345e-16-5.65519853e-16j -7.84095011e-16+3.92047506e-16j]\n",
            " [ 4.89192020e-16-5.13478149e-16j -4.16333634e-17+4.16333634e-16j\n",
            "   1.00000000e+00+4.19581117e-18j ...  4.71844785e-16+4.02455846e-16j\n",
            "   6.93889390e-16-3.53883589e-16j -2.22044605e-16-4.76181594e-16j]\n",
            " ...\n",
            " [ 6.24500451e-16-8.32667268e-17j  2.22044605e-16+7.97972799e-16j\n",
            "   4.64905892e-16-4.02455846e-16j ...  1.00000000e+00-9.18932078e-19j\n",
            "  -2.49800181e-16+4.78783679e-16j  2.91433544e-16-3.05311332e-16j]\n",
            " [-7.56339436e-16-4.44089210e-16j -6.45317133e-16+5.65519853e-16j\n",
            "   6.81746326e-16+3.53883589e-16j ... -2.49800181e-16-5.06539255e-16j\n",
            "   1.00000000e+00-1.23589763e-18j -8.46545056e-16+8.85576334e-16j]\n",
            " [ 1.94289029e-16-3.03576608e-16j -7.75421394e-16-3.92047506e-16j\n",
            "  -2.35922393e-16+4.76181594e-16j ...  2.91433544e-16+3.05311332e-16j\n",
            "  -8.46545056e-16-8.76902717e-16j  1.00000000e+00-9.00364469e-19j]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_sv(\n",
        "    state:jnp.ndarray,\n",
        "    observable:jnp.ndarray\n",
        "    ):\n",
        "  \"\"\"\n",
        "  Measure a statevector with a Hermitian observable.\n",
        "  Note: No checking Hermitianicity of the observable or whether the observable\n",
        "  has all real eigenvalues or not\n",
        "  \"\"\"\n",
        "  expectation_value = jnp.dot(jnp.conj(state.T), jnp.dot(observable, state))\n",
        "  return jnp.real(expectation_value)\n",
        "\n",
        "def measure_dm(\n",
        "    rho:jnp.ndarray,\n",
        "    observable:jnp.ndarray\n",
        "):\n",
        "  \"\"\"\n",
        "  Measure a density matrix with a Hermitian observable.\n",
        "  Note: No checking Hermitianicity of the observable or whether the observable\n",
        "  has all real eigenvalues or not.\n",
        "  \"\"\"\n",
        "  product = jnp.dot(rho, observable)\n",
        "\n",
        "  # Calculate the trace, which is the sum of diagonal elements\n",
        "  trace = jnp.trace(product)\n",
        "\n",
        "  # The expectation value should be real for physical observables\n",
        "  return jnp.real(trace)\n",
        "\n",
        "vmap_measure_sv = jax.vmap(measure_sv, in_axes=(None, 0), out_axes=0)\n",
        "vmap_measure_dm = jax.vmap(measure_dm, in_axes=(None, 0), out_axes=0)\n",
        "\n",
        "def bitstring_to_state(bitstring:str):\n",
        "  \"\"\"\n",
        "  Convert a bit string, like '0101001' or '+-+-101'\n",
        "  to a statevector. Each character in the bitstring must be among\n",
        "  0, 1, + and -\n",
        "  \"\"\"\n",
        "  assert len(bitstring)>0\n",
        "  for c in bitstring:\n",
        "    assert c in ['0', '1', '+', '-']\n",
        "  single_qubit_states = [ket[c] for c in bitstring]\n",
        "  return tensor_product(*single_qubit_states)"
      ],
      "metadata": {
        "id": "cJ8epBAvc_77"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The QNN\n",
        "\n",
        "With data re-uploading\n",
        "\n",
        "$$\n",
        "|{\\varphi(\\theta,t)}\\rangle = \\Pi_n (\\mathrm{ParameterisedLayers}(\\theta_n) e^{-\\frac{it_n}{2}M} )|+\\rangle^{\\otimes 5}\n",
        "$$"
      ],
      "metadata": {
        "id": "BMtaAqSXdDHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def qnn_hamevo(\n",
        "    params:jnp.ndarray,\n",
        "    t:jnp.ndarray,\n",
        "    img:jnp.ndarray\n",
        ")->jnp.ndarray:\n",
        "  \"\"\"\n",
        "  A QNN that takes (M+M^T)/2\n",
        "  as input, where M is the (rescaled) original image,\n",
        "  as well as a trainable parameter t,\n",
        "  and parameters for trainable layers\n",
        "  and output an array of 2 elements representing classification logits\n",
        "  \"\"\"\n",
        "  single_op_params = 4**5-1\n",
        "\n",
        "  n_outer_layers = len(t)\n",
        "  n_inner_layers = (len(params)//single_op_params)//n_outer_layers\n",
        "  state = tensor_product(ket['+'], ket['+'], ket['+'], ket['+'], ket['+'])\n",
        "  for i in range(n_outer_layers):\n",
        "    state = jnp.dot(\n",
        "      img_hermitian_evolve(img, t[i]),\n",
        "      state\n",
        "      )\n",
        "    inner_layer_params = params[i*(single_op_params*n_inner_layers):(i+1)*(single_op_params*n_inner_layers)]\n",
        "    for j in range(n_inner_layers):\n",
        "      state = jnp.dot(\n",
        "          #brickwall_su4_5q_single_layer(inner_layer_params[j*single_op_params:(j+1)*single_op_params]),\n",
        "          su32_op(inner_layer_params[j*single_op_params:(j+1)*single_op_params]),\n",
        "          state\n",
        "      )\n",
        "  return vmap_measure_sv(state, jnp.asarray(observables_8_cls_5q))\n",
        "\n",
        "\n",
        "\n",
        "print(\n",
        "    qnn_hamevo(\n",
        "        jax.random.normal(shape=[( 4**5-1)*15], key=jrng_key),\n",
        "        jax.random.normal(shape=[15], key=jrng_key),\n",
        "        dummy_x[0]\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdyCKp2pdE8j",
        "outputId": "20b8cdcb-36f0-4c9e-c78c-79ebe2755b77"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.07191345 0.04716812 0.02480664 0.14504781 0.04153891 0.07923675\n",
            " 0.04960717 0.08944923]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "eFjfEttbdNEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def compute_out(weight,t, features, labels):\n",
        "    \"\"\"Computes the output of the corresponding label in the qcnn\"\"\"\n",
        "    out = lambda weight,t, feature, label: qnn_hamevo(weight,t, feature)\n",
        "    return jax.vmap(out, in_axes=(None,None,  0, 0), out_axes=0)(\n",
        "        weight,t, features, labels\n",
        "    )\n",
        "\n",
        "\n",
        "def compute_accuracy(weight,t, features, labels):\n",
        "    \"\"\"Computes the accuracy over the provided features and labels\"\"\"\n",
        "    out = compute_out(weight,t, features, labels)\n",
        "    pred = jnp.argmax(out, axis = 1)\n",
        "    return jnp.sum(jnp.array(pred == labels).astype(int)) / len(out)\n",
        "\n",
        "\n",
        "def compute_cost(weight,t, features, labels):\n",
        "    \"\"\"Computes the cost over the provided features and labels\"\"\"\n",
        "    logits = compute_out(weight,t, features, labels)\n",
        "    return jnp.nanmean(optax.softmax_cross_entropy_with_integer_labels(logits, labels))\n",
        "\n",
        "\n",
        "value_and_grad = jax.jit(jax.value_and_grad(compute_cost, argnums=[0,1]))"
      ],
      "metadata": {
        "id": "6Pc1I3fqdOX_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_OUTER_LAYERS = 10\n",
        "N_INNER_LAYERS = 1\n",
        "N_LAYERS = N_OUTER_LAYERS*N_INNER_LAYERS\n",
        "SINGLE_OP_PARAMS  = 4**5-1\n",
        "\n",
        "def init_weights():\n",
        "    return jax.random.normal(shape=[SINGLE_OP_PARAMS*N_LAYERS], key=jrng_key),jax.random.normal(shape=[N_OUTER_LAYERS], key=jrng_key)\n",
        "\n",
        "# def init_weights(alpha=0.5, beta=2.0):\n",
        "#     # Initialize weights with a Beta distribution skewed towards 0\n",
        "#     weights = jax.random.beta(jrng_key, alpha, beta, shape=[SINGLE_OP_PARAMS*N_LAYERS])\n",
        "#     biases = jax.random.beta(jrng_key, alpha, beta, shape=[N_OUTER_LAYERS])\n",
        "#     return weights, biases"
      ],
      "metadata": {
        "id": "aI13rv6DdRJO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select data\n",
        "labels = [0,1,2,3,4,5,6,7,8,9]\n",
        "indices_train = [idx for idx, target in enumerate(train_dataset.targets) if target in labels]\n",
        "indices_test = [idx for idx, target in enumerate(test_dataset.targets) if target in labels]\n",
        "\n",
        "N_TRAIN = len(indices_train)\n",
        "N_TEST = len(indices_test)\n",
        "\n",
        "print(\n",
        "    f\"Training with: {N_TRAIN}; Testing with: {N_TEST}\"\n",
        ")\n",
        "\n",
        "def train_vqc(batchsize:int, n_epochs:int, seed:int=1701):\n",
        "  start = time.time()\n",
        "  pnp.random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  # load data\n",
        "  labels = [0,1,2,3,4,5,6,7,8,9]\n",
        "  indices_train = [idx for idx, target in enumerate(train_dataset.targets) if target in labels]\n",
        "  indices_test = [idx for idx, target in enumerate(test_dataset.targets) if target in labels]\n",
        "  trainloader = torch.utils.data.DataLoader(\n",
        "  torch.utils.data.Subset(train_dataset, indices_train), batch_size=batchsize, shuffle=True\n",
        ")\n",
        "  testloader = torch.utils.data.DataLoader(\n",
        "  torch.utils.data.Subset(test_dataset, indices_test), batch_size=batchsize, shuffle=True\n",
        ")\n",
        "  # Exponential decay of the learning rate.\n",
        "  scheduler = optax.exponential_decay(\n",
        "    init_value=0.01,\n",
        "    transition_steps=n_epochs,\n",
        "    decay_rate=0.99)\n",
        "\n",
        "  # Combining gradient transforms using `optax.chain`.\n",
        "  gradient_transform = optax.chain(\n",
        "    optax.clip(1.0),\n",
        "    optax.scale_by_adam(),  # Use the updates from adam.\n",
        "    optax.scale_by_schedule(scheduler),  # Use the learning rate from the scheduler.\n",
        "    # Scale updates by -1 since optax.apply_updates is additive and we want to descend on the loss.\n",
        "    optax.scale(-1.0)\n",
        "  )\n",
        "  # init weights and optimizer\n",
        "  weights, weights_last = init_weights() # for normal\n",
        "  # weights, weights_last = init_weights(0.5,2.0) # for beta\n",
        "\n",
        "  opt_state = gradient_transform.init((weights, weights_last))\n",
        "  #data containers\n",
        "  train_cost_epochs, test_cost_epochs, train_acc_epochs, test_acc_epochs = [], [], [], []\n",
        "  for step in range(n_epochs):\n",
        "        train_cost_batches = []\n",
        "        train_acc_batches = []\n",
        "        test_cost_batches = []\n",
        "        test_acc_batches = []\n",
        "        epoch_start = time.time()\n",
        "        print(f\"Training at Epoch {step+1}/{n_epochs}, Train batches {len(trainloader)}, Test batches {len(testloader)}......\")\n",
        "        for batch, (x_train, y_train) in enumerate(trainloader):\n",
        "          batch_start = time.time()\n",
        "          # Training step with (adam) optimizer\n",
        "          x_train, y_train = jnp.asarray(x_train.numpy()), jnp.asarray(y_train.numpy())\n",
        "          train_cost, grad_circuit = value_and_grad(weights, weights_last, x_train, y_train)\n",
        "          updates, opt_state = gradient_transform.update(grad_circuit, opt_state)\n",
        "          weights, weights_last = optax.apply_updates((weights, weights_last), updates)\n",
        "          train_acc = compute_accuracy(weights, weights_last, x_train, y_train)\n",
        "          train_cost_batches.append(train_cost)\n",
        "          train_acc_batches.append(train_acc)\n",
        "          if len(trainloader)<= 5 or (batch+1)%5==0:\n",
        "            print(f\"Training at Epoch {step+1}/{n_epochs}, Batch {batch+1}, Cost {train_cost}, Acc {train_acc}. Time {time.time()-batch_start}\")\n",
        "\n",
        "\n",
        "        train_cost_epochs.append(np.mean(train_cost_batches))\n",
        "        train_acc_epochs.append(np.mean(train_acc_batches))\n",
        "\n",
        "\n",
        "        # load test data\n",
        "        for batch, (x_test, y_test) in enumerate(testloader):\n",
        "          batch_start = time.time()\n",
        "          x_test, y_test = jnp.asarray(x_test.numpy()), jnp.asarray(y_test.numpy())\n",
        "          # compute accuracy and cost on testing data\n",
        "          test_out = compute_out(weights, weights_last, x_test, y_test)\n",
        "          test_pred = jnp.argmax(test_out, axis=1)\n",
        "          test_acc = jnp.sum(jnp.array(test_pred == y_test).astype(int)) / len(test_out)\n",
        "          test_cost = jnp.nanmean(optax.softmax_cross_entropy_with_integer_labels(test_out, y_test))\n",
        "          test_cost_batches.append(test_cost)\n",
        "          test_acc_batches.append(test_acc)\n",
        "          if len(testloader)<= 5 or (batch+1)%5==0:\n",
        "            print(f\"Testing at Epoch {step+1}/{n_epochs}, Batch {batch+1}, Cost {test_cost}, Acc {test_acc}. Time {time.time()-batch_start}\")\n",
        "        test_acc_epochs.append(np.mean(test_acc_batches))\n",
        "        test_cost = np.mean(test_cost_batches)\n",
        "        test_cost_epochs.append(test_cost)\n",
        "        print(\"......\")\n",
        "        print(f\"Epoch {step+1}/{n_epochs}, Train: Cost {np.mean(train_cost_batches)}, Acc {np.mean(train_acc_batches)}\")\n",
        "        print(f\"Epoch {step+1}/{n_epochs}, Test: Cost {test_cost}, Acc {test_acc}. Time {time.time()-epoch_start}\")\n",
        "        print(\"=-=\"*10)\n",
        "\n",
        "  return dict(\n",
        "        n_train=[N_TRAIN] * n_epochs,\n",
        "        step=np.arange(1, n_epochs + 1, dtype=int).tolist(),\n",
        "        train_cost=[c.astype(float) for c in train_cost_epochs],\n",
        "        train_acc=[c.astype(float) for c in train_acc_epochs],\n",
        "        test_cost=[c.astype(float) for c in test_cost_epochs],\n",
        "        test_acc=[c.astype(float) for c in test_acc_epochs],\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLyRg7EydVgN",
        "outputId": "12805fdc-df3a-4ea8-dea4-b9aba37873ce"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with: 60000; Testing with: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 25\n",
        "n_reps = 1\n",
        "batch_size = 500\n",
        "\n",
        "train_sizes = [N_TRAIN]\n",
        "\n",
        "def run_iterations():\n",
        "    results_df = pd.DataFrame(\n",
        "        columns=[\"train_acc\", \"train_cost\", \"test_acc\", \"test_cost\", \"step\", \"n_train\"]\n",
        "    )\n",
        "\n",
        "    for _ in range(n_reps):\n",
        "        results = train_vqc(n_epochs=n_epochs, batchsize=batch_size)\n",
        "        results_df = pd.concat(\n",
        "            [results_df, pd.DataFrame.from_dict(results)], axis=0, ignore_index=True\n",
        "        )\n",
        "\n",
        "    return results_df\n",
        "\n",
        "results_df = run_iterations()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTZnVAUldvDs",
        "outputId": "ad8b6ff6-c71c-4c0c-c6a1-29a6f57f097b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training at Epoch 1/25, Train batches 120, Test batches 20......\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py:3227: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  x_bar = _convert_element_type(x_bar, x.aval.dtype, x.aval.weak_type)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training at Epoch 1/25, Batch 5, Cost 2.003216240352817, Acc 0.436. Time 1.3248963356018066\n",
            "Training at Epoch 1/25, Batch 10, Cost 1.9433516751534823, Acc 0.496. Time 1.3316748142242432\n",
            "Training at Epoch 1/25, Batch 15, Cost 1.8837191493141519, Acc 0.546. Time 1.3333535194396973\n",
            "Training at Epoch 1/25, Batch 20, Cost 1.8545213152414568, Acc 0.6. Time 1.3434863090515137\n",
            "Training at Epoch 1/25, Batch 25, Cost 1.839890592084288, Acc 0.57. Time 1.349806308746338\n",
            "Training at Epoch 1/25, Batch 30, Cost 1.8244087751423046, Acc 0.578. Time 1.3521993160247803\n",
            "Training at Epoch 1/25, Batch 35, Cost 1.7968751404855594, Acc 0.634. Time 1.3746623992919922\n",
            "Training at Epoch 1/25, Batch 40, Cost 1.7924554639341779, Acc 0.606. Time 1.3577327728271484\n",
            "Training at Epoch 1/25, Batch 45, Cost 1.7857220437166754, Acc 0.62. Time 1.3582608699798584\n",
            "Training at Epoch 1/25, Batch 50, Cost 1.765951797879542, Acc 0.654. Time 1.3485054969787598\n",
            "Training at Epoch 1/25, Batch 55, Cost 1.771706463782638, Acc 0.64. Time 1.3493895530700684\n",
            "Training at Epoch 1/25, Batch 60, Cost 1.7650740679956392, Acc 0.62. Time 1.3566336631774902\n",
            "Training at Epoch 1/25, Batch 65, Cost 1.7562780570482528, Acc 0.604. Time 1.342073917388916\n",
            "Training at Epoch 1/25, Batch 70, Cost 1.7428933919173115, Acc 0.636. Time 1.3517141342163086\n",
            "Training at Epoch 1/25, Batch 75, Cost 1.7313207345474748, Acc 0.654. Time 1.3556978702545166\n",
            "Training at Epoch 1/25, Batch 80, Cost 1.7493782662326363, Acc 0.662. Time 1.3563852310180664\n",
            "Training at Epoch 1/25, Batch 85, Cost 1.7255981833599625, Acc 0.634. Time 1.3457813262939453\n",
            "Training at Epoch 1/25, Batch 90, Cost 1.7182344662570403, Acc 0.654. Time 1.348362922668457\n",
            "Training at Epoch 1/25, Batch 95, Cost 1.7274305781588883, Acc 0.67. Time 1.349543809890747\n",
            "Training at Epoch 1/25, Batch 100, Cost 1.7170245862380709, Acc 0.66. Time 1.3459553718566895\n",
            "Training at Epoch 1/25, Batch 105, Cost 1.6922674015492143, Acc 0.688. Time 1.3491489887237549\n",
            "Training at Epoch 1/25, Batch 110, Cost 1.7167852157844337, Acc 0.632. Time 1.3464717864990234\n",
            "Training at Epoch 1/25, Batch 115, Cost 1.7021332298574732, Acc 0.674. Time 1.3581178188323975\n",
            "Training at Epoch 1/25, Batch 120, Cost 1.6956650685723753, Acc 0.674. Time 1.3458266258239746\n",
            "Testing at Epoch 1/25, Batch 5, Cost 1.7075229711141227, Acc 0.686. Time 0.34120941162109375\n",
            "Testing at Epoch 1/25, Batch 10, Cost 1.70610666110433, Acc 0.648. Time 0.3441157341003418\n",
            "Testing at Epoch 1/25, Batch 15, Cost 1.6934081970445551, Acc 0.674. Time 0.3393237590789795\n",
            "Testing at Epoch 1/25, Batch 20, Cost 1.6946522499236296, Acc 0.674. Time 0.3427281379699707\n",
            "......\n",
            "Epoch 1/25, Train: Cost 1.787944982106262, Acc 0.6070166666666666\n",
            "Epoch 1/25, Test: Cost 1.70259297994475, Acc 0.674. Time 232.50654649734497\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 2/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 2/25, Batch 5, Cost 1.707177126400037, Acc 0.678. Time 1.3431077003479004\n",
            "Training at Epoch 2/25, Batch 10, Cost 1.6999094085817024, Acc 0.678. Time 1.3476605415344238\n",
            "Training at Epoch 2/25, Batch 15, Cost 1.693365105852483, Acc 0.656. Time 1.3543920516967773\n",
            "Training at Epoch 2/25, Batch 20, Cost 1.709778735936896, Acc 0.652. Time 1.3456060886383057\n",
            "Training at Epoch 2/25, Batch 25, Cost 1.6925808439336194, Acc 0.692. Time 1.364661455154419\n",
            "Training at Epoch 2/25, Batch 30, Cost 1.7014555361179027, Acc 0.672. Time 1.347029685974121\n",
            "Training at Epoch 2/25, Batch 35, Cost 1.6848507927797387, Acc 0.672. Time 1.343862771987915\n",
            "Training at Epoch 2/25, Batch 40, Cost 1.6891037093253083, Acc 0.634. Time 1.3431127071380615\n",
            "Training at Epoch 2/25, Batch 45, Cost 1.7015170202565189, Acc 0.636. Time 1.3432650566101074\n",
            "Training at Epoch 2/25, Batch 50, Cost 1.6682393516726413, Acc 0.682. Time 1.3543076515197754\n",
            "Training at Epoch 2/25, Batch 55, Cost 1.6993123360568214, Acc 0.67. Time 1.3440265655517578\n",
            "Training at Epoch 2/25, Batch 60, Cost 1.68911956983025, Acc 0.672. Time 1.3621397018432617\n",
            "Training at Epoch 2/25, Batch 65, Cost 1.690162994096081, Acc 0.7. Time 1.3449091911315918\n",
            "Training at Epoch 2/25, Batch 70, Cost 1.6845249138346878, Acc 0.706. Time 1.3452248573303223\n",
            "Training at Epoch 2/25, Batch 75, Cost 1.6763556432802285, Acc 0.678. Time 1.3438479900360107\n",
            "Training at Epoch 2/25, Batch 80, Cost 1.6598967507593128, Acc 0.658. Time 1.3458240032196045\n",
            "Training at Epoch 2/25, Batch 85, Cost 1.6943170311680074, Acc 0.68. Time 1.3427379131317139\n",
            "Training at Epoch 2/25, Batch 90, Cost 1.6927249392164, Acc 0.686. Time 1.3465099334716797\n",
            "Training at Epoch 2/25, Batch 95, Cost 1.6857630908682435, Acc 0.68. Time 1.3586342334747314\n",
            "Training at Epoch 2/25, Batch 100, Cost 1.6699521581090304, Acc 0.71. Time 1.3472392559051514\n",
            "Training at Epoch 2/25, Batch 105, Cost 1.670148488176027, Acc 0.676. Time 1.362959384918213\n",
            "Training at Epoch 2/25, Batch 110, Cost 1.6803868935341755, Acc 0.666. Time 1.345869779586792\n",
            "Training at Epoch 2/25, Batch 115, Cost 1.6681575959361439, Acc 0.672. Time 1.3490138053894043\n",
            "Training at Epoch 2/25, Batch 120, Cost 1.6895460516499707, Acc 0.638. Time 1.3434700965881348\n",
            "Testing at Epoch 2/25, Batch 5, Cost 1.673746501338515, Acc 0.65. Time 0.3400547504425049\n",
            "Testing at Epoch 2/25, Batch 10, Cost 1.6716945759024877, Acc 0.662. Time 0.3372972011566162\n",
            "Testing at Epoch 2/25, Batch 15, Cost 1.6682015045411183, Acc 0.678. Time 0.335115909576416\n",
            "Testing at Epoch 2/25, Batch 20, Cost 1.6605594425631947, Acc 0.646. Time 0.33719325065612793\n",
            "......\n",
            "Epoch 2/25, Train: Cost 1.6899900161140036, Acc 0.6712333333333333\n",
            "Epoch 2/25, Test: Cost 1.6686842956579997, Acc 0.646. Time 181.95184326171875\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 3/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 3/25, Batch 5, Cost 1.6775007527305748, Acc 0.66. Time 1.3488843441009521\n",
            "Training at Epoch 3/25, Batch 10, Cost 1.679710849964466, Acc 0.678. Time 1.3306334018707275\n",
            "Training at Epoch 3/25, Batch 15, Cost 1.647463995750972, Acc 0.714. Time 1.3337242603302002\n",
            "Training at Epoch 3/25, Batch 20, Cost 1.6670928538687, Acc 0.66. Time 1.3352618217468262\n",
            "Training at Epoch 3/25, Batch 25, Cost 1.6820322579394449, Acc 0.672. Time 1.3325860500335693\n",
            "Training at Epoch 3/25, Batch 30, Cost 1.6628205644108058, Acc 0.71. Time 1.3358025550842285\n",
            "Training at Epoch 3/25, Batch 35, Cost 1.6702919049810545, Acc 0.692. Time 1.3339333534240723\n",
            "Training at Epoch 3/25, Batch 40, Cost 1.6872831315180608, Acc 0.646. Time 1.353954792022705\n",
            "Training at Epoch 3/25, Batch 45, Cost 1.6644141127500023, Acc 0.69. Time 1.3339128494262695\n",
            "Training at Epoch 3/25, Batch 50, Cost 1.6871774862106446, Acc 0.61. Time 1.3506855964660645\n",
            "Training at Epoch 3/25, Batch 55, Cost 1.6607159331183245, Acc 0.712. Time 1.3297998905181885\n",
            "Training at Epoch 3/25, Batch 60, Cost 1.6731936821414526, Acc 0.7. Time 1.332573652267456\n",
            "Training at Epoch 3/25, Batch 65, Cost 1.6856942181900683, Acc 0.676. Time 1.3423640727996826\n",
            "Training at Epoch 3/25, Batch 70, Cost 1.662066175190765, Acc 0.684. Time 1.344656229019165\n",
            "Training at Epoch 3/25, Batch 75, Cost 1.6777555866802965, Acc 0.662. Time 1.3612515926361084\n",
            "Training at Epoch 3/25, Batch 80, Cost 1.6738444160079633, Acc 0.636. Time 1.3421764373779297\n",
            "Training at Epoch 3/25, Batch 85, Cost 1.6723790672989647, Acc 0.68. Time 1.359874963760376\n",
            "Training at Epoch 3/25, Batch 90, Cost 1.6487512387777459, Acc 0.678. Time 1.3410882949829102\n",
            "Training at Epoch 3/25, Batch 95, Cost 1.6564505802018117, Acc 0.694. Time 1.3400075435638428\n",
            "Training at Epoch 3/25, Batch 100, Cost 1.6786846997659193, Acc 0.67. Time 1.3388950824737549\n",
            "Training at Epoch 3/25, Batch 105, Cost 1.668329504746353, Acc 0.68. Time 1.3380160331726074\n",
            "Training at Epoch 3/25, Batch 110, Cost 1.6505848753445025, Acc 0.68. Time 1.3419177532196045\n",
            "Training at Epoch 3/25, Batch 115, Cost 1.6636524477710966, Acc 0.674. Time 1.3404934406280518\n",
            "Training at Epoch 3/25, Batch 120, Cost 1.654332174474861, Acc 0.712. Time 1.353621006011963\n",
            "Testing at Epoch 3/25, Batch 5, Cost 1.6576778847733653, Acc 0.662. Time 0.3380281925201416\n",
            "Testing at Epoch 3/25, Batch 10, Cost 1.6679945075101803, Acc 0.672. Time 0.3377852439880371\n",
            "Testing at Epoch 3/25, Batch 15, Cost 1.6622682831002553, Acc 0.68. Time 0.3387761116027832\n",
            "Testing at Epoch 3/25, Batch 20, Cost 1.6368372830558464, Acc 0.702. Time 0.33901548385620117\n",
            "......\n",
            "Epoch 3/25, Train: Cost 1.6680028702020637, Acc 0.6819166666666666\n",
            "Epoch 3/25, Test: Cost 1.652335143445337, Acc 0.702. Time 181.2843804359436\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 4/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 4/25, Batch 5, Cost 1.6562247632563196, Acc 0.688. Time 1.3336124420166016\n",
            "Training at Epoch 4/25, Batch 10, Cost 1.6725030490726092, Acc 0.676. Time 1.3308260440826416\n",
            "Training at Epoch 4/25, Batch 15, Cost 1.6487756825900768, Acc 0.686. Time 1.3410460948944092\n",
            "Training at Epoch 4/25, Batch 20, Cost 1.6623818451059458, Acc 0.682. Time 1.3365123271942139\n",
            "Training at Epoch 4/25, Batch 25, Cost 1.648646864463437, Acc 0.734. Time 1.3410513401031494\n",
            "Training at Epoch 4/25, Batch 30, Cost 1.6452569343678975, Acc 0.684. Time 1.347217321395874\n",
            "Training at Epoch 4/25, Batch 35, Cost 1.6535482750067503, Acc 0.726. Time 1.3416242599487305\n",
            "Training at Epoch 4/25, Batch 40, Cost 1.6558465104728655, Acc 0.71. Time 1.3394932746887207\n",
            "Training at Epoch 4/25, Batch 45, Cost 1.64657854160373, Acc 0.708. Time 1.3371515274047852\n",
            "Training at Epoch 4/25, Batch 50, Cost 1.6681632385058662, Acc 0.65. Time 1.3322088718414307\n",
            "Training at Epoch 4/25, Batch 55, Cost 1.6500098238907663, Acc 0.704. Time 1.3382201194763184\n",
            "Training at Epoch 4/25, Batch 60, Cost 1.6441620382005144, Acc 0.722. Time 1.3331170082092285\n",
            "Training at Epoch 4/25, Batch 65, Cost 1.6712906154757392, Acc 0.692. Time 1.3463037014007568\n",
            "Training at Epoch 4/25, Batch 70, Cost 1.6461384612948637, Acc 0.73. Time 1.3349170684814453\n",
            "Training at Epoch 4/25, Batch 75, Cost 1.6600210300749454, Acc 0.7. Time 1.3523542881011963\n",
            "Training at Epoch 4/25, Batch 80, Cost 1.6590791298761232, Acc 0.672. Time 1.3323774337768555\n",
            "Training at Epoch 4/25, Batch 85, Cost 1.6562023766472633, Acc 0.662. Time 1.337611436843872\n",
            "Training at Epoch 4/25, Batch 90, Cost 1.6373985212258475, Acc 0.694. Time 1.3297836780548096\n",
            "Training at Epoch 4/25, Batch 95, Cost 1.6732315036990775, Acc 0.67. Time 1.3388502597808838\n",
            "Training at Epoch 4/25, Batch 100, Cost 1.665137066371315, Acc 0.704. Time 1.3313336372375488\n",
            "Training at Epoch 4/25, Batch 105, Cost 1.6608596763172367, Acc 0.678. Time 1.3373560905456543\n",
            "Training at Epoch 4/25, Batch 110, Cost 1.6512919439119043, Acc 0.682. Time 1.336306095123291\n",
            "Training at Epoch 4/25, Batch 115, Cost 1.6687093266359987, Acc 0.664. Time 1.3350839614868164\n",
            "Training at Epoch 4/25, Batch 120, Cost 1.6559248588714472, Acc 0.708. Time 1.3548963069915771\n",
            "Testing at Epoch 4/25, Batch 5, Cost 1.6607049153103528, Acc 0.682. Time 0.3387300968170166\n",
            "Testing at Epoch 4/25, Batch 10, Cost 1.6567014617923437, Acc 0.68. Time 0.33673954010009766\n",
            "Testing at Epoch 4/25, Batch 15, Cost 1.6624303212547316, Acc 0.69. Time 0.3391757011413574\n",
            "Testing at Epoch 4/25, Batch 20, Cost 1.6449658749915874, Acc 0.708. Time 0.3357417583465576\n",
            "......\n",
            "Epoch 4/25, Train: Cost 1.6543450383801905, Acc 0.68835\n",
            "Epoch 4/25, Test: Cost 1.6471267492260704, Acc 0.708. Time 180.47691774368286\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 5/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 5/25, Batch 5, Cost 1.6586626245007616, Acc 0.656. Time 1.3349525928497314\n",
            "Training at Epoch 5/25, Batch 10, Cost 1.6477457948093983, Acc 0.658. Time 1.3424265384674072\n",
            "Training at Epoch 5/25, Batch 15, Cost 1.657806786700659, Acc 0.696. Time 1.3377056121826172\n",
            "Training at Epoch 5/25, Batch 20, Cost 1.6418328564578297, Acc 0.714. Time 1.3366353511810303\n",
            "Training at Epoch 5/25, Batch 25, Cost 1.6270203901932463, Acc 0.73. Time 1.332313060760498\n",
            "Training at Epoch 5/25, Batch 30, Cost 1.6554591944352126, Acc 0.704. Time 1.3422009944915771\n",
            "Training at Epoch 5/25, Batch 35, Cost 1.6342720154120562, Acc 0.69. Time 1.3304071426391602\n",
            "Training at Epoch 5/25, Batch 40, Cost 1.6301346766111406, Acc 0.688. Time 1.3519408702850342\n",
            "Training at Epoch 5/25, Batch 45, Cost 1.6459836126355651, Acc 0.692. Time 1.3321623802185059\n",
            "Training at Epoch 5/25, Batch 50, Cost 1.654698483264504, Acc 0.682. Time 1.336735725402832\n",
            "Training at Epoch 5/25, Batch 55, Cost 1.61722878389603, Acc 0.728. Time 1.331026315689087\n",
            "Training at Epoch 5/25, Batch 60, Cost 1.66921160343393, Acc 0.666. Time 1.3283898830413818\n",
            "Training at Epoch 5/25, Batch 65, Cost 1.6472279073641118, Acc 0.676. Time 1.331782341003418\n",
            "Training at Epoch 5/25, Batch 70, Cost 1.6581226788613344, Acc 0.684. Time 1.3304815292358398\n",
            "Training at Epoch 5/25, Batch 75, Cost 1.6491363292151222, Acc 0.682. Time 1.3470032215118408\n",
            "Training at Epoch 5/25, Batch 80, Cost 1.6381419833403756, Acc 0.696. Time 1.332221508026123\n",
            "Training at Epoch 5/25, Batch 85, Cost 1.6516651839576688, Acc 0.68. Time 1.3481452465057373\n",
            "Training at Epoch 5/25, Batch 90, Cost 1.6453875118945387, Acc 0.72. Time 1.3332273960113525\n",
            "Training at Epoch 5/25, Batch 95, Cost 1.633187931263343, Acc 0.686. Time 1.3288161754608154\n",
            "Training at Epoch 5/25, Batch 100, Cost 1.6512100052174028, Acc 0.692. Time 1.3345201015472412\n",
            "Training at Epoch 5/25, Batch 105, Cost 1.6552513558444464, Acc 0.664. Time 1.3324010372161865\n",
            "Training at Epoch 5/25, Batch 110, Cost 1.6104550789355625, Acc 0.718. Time 1.3367502689361572\n",
            "Training at Epoch 5/25, Batch 115, Cost 1.6428372825902327, Acc 0.712. Time 1.3351078033447266\n",
            "Training at Epoch 5/25, Batch 120, Cost 1.64887607555266, Acc 0.714. Time 1.3483119010925293\n",
            "Testing at Epoch 5/25, Batch 5, Cost 1.632900695577671, Acc 0.716. Time 0.33669447898864746\n",
            "Testing at Epoch 5/25, Batch 10, Cost 1.6389723424691907, Acc 0.702. Time 0.3366096019744873\n",
            "Testing at Epoch 5/25, Batch 15, Cost 1.6427271376852304, Acc 0.688. Time 0.3374779224395752\n",
            "Testing at Epoch 5/25, Batch 20, Cost 1.6249432514809223, Acc 0.714. Time 0.33559441566467285\n",
            "......\n",
            "Epoch 5/25, Train: Cost 1.6455913041466266, Acc 0.6926333333333333\n",
            "Epoch 5/25, Test: Cost 1.6366123660361194, Acc 0.714. Time 180.23058366775513\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 6/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 6/25, Batch 5, Cost 1.622898356667286, Acc 0.718. Time 1.3329439163208008\n",
            "Training at Epoch 6/25, Batch 10, Cost 1.641905768477213, Acc 0.71. Time 1.346060037612915\n",
            "Training at Epoch 6/25, Batch 15, Cost 1.6428434154799665, Acc 0.676. Time 1.3466453552246094\n",
            "Training at Epoch 6/25, Batch 20, Cost 1.6528702745158539, Acc 0.724. Time 1.3585004806518555\n",
            "Training at Epoch 6/25, Batch 25, Cost 1.6428394337073542, Acc 0.714. Time 1.3473520278930664\n",
            "Training at Epoch 6/25, Batch 30, Cost 1.6627311168713168, Acc 0.68. Time 1.3603143692016602\n",
            "Training at Epoch 6/25, Batch 35, Cost 1.636792062468522, Acc 0.684. Time 1.35013747215271\n",
            "Training at Epoch 6/25, Batch 40, Cost 1.6659229530362807, Acc 0.7. Time 1.346313714981079\n",
            "Training at Epoch 6/25, Batch 45, Cost 1.619885017227231, Acc 0.696. Time 1.3436493873596191\n",
            "Training at Epoch 6/25, Batch 50, Cost 1.6395061448348383, Acc 0.71. Time 1.3448092937469482\n",
            "Training at Epoch 6/25, Batch 55, Cost 1.636055066617329, Acc 0.694. Time 1.3483998775482178\n",
            "Training at Epoch 6/25, Batch 60, Cost 1.650531040872143, Acc 0.67. Time 1.3454809188842773\n",
            "Training at Epoch 6/25, Batch 65, Cost 1.6332718664143087, Acc 0.668. Time 1.3578813076019287\n",
            "Training at Epoch 6/25, Batch 70, Cost 1.6473239349712396, Acc 0.696. Time 1.3450069427490234\n",
            "Training at Epoch 6/25, Batch 75, Cost 1.6295686417120105, Acc 0.706. Time 1.3495876789093018\n",
            "Training at Epoch 6/25, Batch 80, Cost 1.6319745762957139, Acc 0.702. Time 1.3452589511871338\n",
            "Training at Epoch 6/25, Batch 85, Cost 1.6419959328458729, Acc 0.682. Time 1.3454153537750244\n",
            "Training at Epoch 6/25, Batch 90, Cost 1.6284206530019099, Acc 0.686. Time 1.3465561866760254\n",
            "Training at Epoch 6/25, Batch 95, Cost 1.6295014589485197, Acc 0.704. Time 1.3469109535217285\n",
            "Training at Epoch 6/25, Batch 100, Cost 1.6290444596587155, Acc 0.674. Time 1.3582522869110107\n",
            "Training at Epoch 6/25, Batch 105, Cost 1.6254694918445844, Acc 0.706. Time 1.3453819751739502\n",
            "Training at Epoch 6/25, Batch 110, Cost 1.6551321650152504, Acc 0.67. Time 1.3587737083435059\n",
            "Training at Epoch 6/25, Batch 115, Cost 1.62401643413778, Acc 0.664. Time 1.3439404964447021\n",
            "Training at Epoch 6/25, Batch 120, Cost 1.6182726165450132, Acc 0.744. Time 1.344430685043335\n",
            "Testing at Epoch 6/25, Batch 5, Cost 1.6313693864847822, Acc 0.686. Time 0.3380162715911865\n",
            "Testing at Epoch 6/25, Batch 10, Cost 1.6234371036595723, Acc 0.698. Time 0.33891725540161133\n",
            "Testing at Epoch 6/25, Batch 15, Cost 1.6074024651156542, Acc 0.748. Time 0.3388023376464844\n",
            "Testing at Epoch 6/25, Batch 20, Cost 1.6123764668270864, Acc 0.71. Time 0.3428468704223633\n",
            "......\n",
            "Epoch 6/25, Train: Cost 1.6390507002763857, Acc 0.6957500000000001\n",
            "Epoch 6/25, Test: Cost 1.626210449116563, Acc 0.71. Time 181.52742648124695\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 7/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 7/25, Batch 5, Cost 1.6500226087218763, Acc 0.676. Time 1.3441429138183594\n",
            "Training at Epoch 7/25, Batch 10, Cost 1.6233348753669277, Acc 0.694. Time 1.3577775955200195\n",
            "Training at Epoch 7/25, Batch 15, Cost 1.640237476206501, Acc 0.7. Time 1.3451669216156006\n",
            "Training at Epoch 7/25, Batch 20, Cost 1.6221648700343747, Acc 0.71. Time 1.3487679958343506\n",
            "Training at Epoch 7/25, Batch 25, Cost 1.6214727773599884, Acc 0.696. Time 1.346107006072998\n",
            "Training at Epoch 7/25, Batch 30, Cost 1.626766476239825, Acc 0.698. Time 1.3417315483093262\n",
            "Training at Epoch 7/25, Batch 35, Cost 1.6253952336272606, Acc 0.702. Time 1.3468539714813232\n",
            "Training at Epoch 7/25, Batch 40, Cost 1.6373000253658117, Acc 0.69. Time 1.3484323024749756\n",
            "Training at Epoch 7/25, Batch 45, Cost 1.620031669242188, Acc 0.696. Time 1.3601396083831787\n",
            "Training at Epoch 7/25, Batch 50, Cost 1.6253809468593625, Acc 0.674. Time 1.3527758121490479\n",
            "Training at Epoch 7/25, Batch 55, Cost 1.6437237418794401, Acc 0.68. Time 1.3595855236053467\n",
            "Training at Epoch 7/25, Batch 60, Cost 1.6511353450011126, Acc 0.648. Time 1.3483774662017822\n",
            "Training at Epoch 7/25, Batch 65, Cost 1.6372358193843872, Acc 0.7. Time 1.344935417175293\n",
            "Training at Epoch 7/25, Batch 70, Cost 1.627006665129961, Acc 0.726. Time 1.344266653060913\n",
            "Training at Epoch 7/25, Batch 75, Cost 1.615491424410637, Acc 0.7. Time 1.345594882965088\n",
            "Training at Epoch 7/25, Batch 80, Cost 1.6348706232376047, Acc 0.72. Time 1.3462564945220947\n",
            "Training at Epoch 7/25, Batch 85, Cost 1.6417095830461734, Acc 0.684. Time 1.343451976776123\n",
            "Training at Epoch 7/25, Batch 90, Cost 1.6336407419218661, Acc 0.738. Time 1.361844778060913\n",
            "Training at Epoch 7/25, Batch 95, Cost 1.609059589007127, Acc 0.708. Time 1.3462612628936768\n",
            "Training at Epoch 7/25, Batch 100, Cost 1.6314767951564026, Acc 0.72. Time 1.349822759628296\n",
            "Training at Epoch 7/25, Batch 105, Cost 1.6326270246955152, Acc 0.71. Time 1.3460233211517334\n",
            "Training at Epoch 7/25, Batch 110, Cost 1.6150028191049883, Acc 0.718. Time 1.3461039066314697\n",
            "Training at Epoch 7/25, Batch 115, Cost 1.6253249535278784, Acc 0.688. Time 1.3460652828216553\n",
            "Training at Epoch 7/25, Batch 120, Cost 1.6378744187492402, Acc 0.694. Time 1.3363757133483887\n",
            "Testing at Epoch 7/25, Batch 5, Cost 1.6409504598202813, Acc 0.676. Time 0.3367593288421631\n",
            "Testing at Epoch 7/25, Batch 10, Cost 1.6259680571681407, Acc 0.676. Time 0.33701086044311523\n",
            "Testing at Epoch 7/25, Batch 15, Cost 1.628606963355706, Acc 0.722. Time 0.3425285816192627\n",
            "Testing at Epoch 7/25, Batch 20, Cost 1.6329855360403966, Acc 0.66. Time 0.3413209915161133\n",
            "......\n",
            "Epoch 7/25, Train: Cost 1.6329061546839467, Acc 0.6968166666666666\n",
            "Epoch 7/25, Test: Cost 1.6262615399265044, Acc 0.66. Time 182.02455067634583\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 8/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 8/25, Batch 5, Cost 1.634704142536088, Acc 0.694. Time 1.3350322246551514\n",
            "Training at Epoch 8/25, Batch 10, Cost 1.6393244051467382, Acc 0.712. Time 1.3413074016571045\n",
            "Training at Epoch 8/25, Batch 15, Cost 1.6357614725187823, Acc 0.704. Time 1.3427867889404297\n",
            "Training at Epoch 8/25, Batch 20, Cost 1.6352768472219026, Acc 0.688. Time 1.3382554054260254\n",
            "Training at Epoch 8/25, Batch 25, Cost 1.6268652759601716, Acc 0.742. Time 1.3403205871582031\n",
            "Training at Epoch 8/25, Batch 30, Cost 1.6187059024283734, Acc 0.724. Time 1.3413114547729492\n",
            "Training at Epoch 8/25, Batch 35, Cost 1.6226116986021066, Acc 0.684. Time 1.35286545753479\n",
            "Training at Epoch 8/25, Batch 40, Cost 1.6397622084276864, Acc 0.702. Time 1.3428161144256592\n",
            "Training at Epoch 8/25, Batch 45, Cost 1.633911721129141, Acc 0.696. Time 1.3527216911315918\n",
            "Training at Epoch 8/25, Batch 50, Cost 1.6225457047006997, Acc 0.682. Time 1.341176986694336\n",
            "Training at Epoch 8/25, Batch 55, Cost 1.6189488571337296, Acc 0.698. Time 1.337289571762085\n",
            "Training at Epoch 8/25, Batch 60, Cost 1.664615433347351, Acc 0.676. Time 1.3377273082733154\n",
            "Training at Epoch 8/25, Batch 65, Cost 1.6330532952653831, Acc 0.706. Time 1.3530633449554443\n",
            "Training at Epoch 8/25, Batch 70, Cost 1.6483480673623998, Acc 0.678. Time 1.3519301414489746\n",
            "Training at Epoch 8/25, Batch 75, Cost 1.6318432567018044, Acc 0.698. Time 1.3374254703521729\n",
            "Training at Epoch 8/25, Batch 80, Cost 1.606922608527649, Acc 0.73. Time 1.3536436557769775\n",
            "Training at Epoch 8/25, Batch 85, Cost 1.6171423826890887, Acc 0.722. Time 1.3363089561462402\n",
            "Training at Epoch 8/25, Batch 90, Cost 1.625850295499837, Acc 0.704. Time 1.339176893234253\n",
            "Training at Epoch 8/25, Batch 95, Cost 1.6016435758685135, Acc 0.696. Time 1.3390955924987793\n",
            "Training at Epoch 8/25, Batch 100, Cost 1.6199084133001833, Acc 0.696. Time 1.3421430587768555\n",
            "Training at Epoch 8/25, Batch 105, Cost 1.6216334680857614, Acc 0.718. Time 1.3467023372650146\n",
            "Training at Epoch 8/25, Batch 110, Cost 1.616122103647262, Acc 0.718. Time 1.3421530723571777\n",
            "Training at Epoch 8/25, Batch 115, Cost 1.6421536541649768, Acc 0.682. Time 1.3509478569030762\n",
            "Training at Epoch 8/25, Batch 120, Cost 1.6336141609634394, Acc 0.702. Time 1.3392207622528076\n",
            "Testing at Epoch 8/25, Batch 5, Cost 1.600038128671721, Acc 0.71. Time 0.33753037452697754\n",
            "Testing at Epoch 8/25, Batch 10, Cost 1.6293850772880765, Acc 0.688. Time 0.3385341167449951\n",
            "Testing at Epoch 8/25, Batch 15, Cost 1.6356310046703266, Acc 0.68. Time 0.3415224552154541\n",
            "Testing at Epoch 8/25, Batch 20, Cost 1.6150896770987837, Acc 0.706. Time 0.3380725383758545\n",
            "......\n",
            "Epoch 8/25, Train: Cost 1.6285453865359645, Acc 0.6986833333333334\n",
            "Epoch 8/25, Test: Cost 1.6214179083671105, Acc 0.706. Time 181.12184739112854\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 9/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 9/25, Batch 5, Cost 1.6132670750432914, Acc 0.706. Time 1.3386051654815674\n",
            "Training at Epoch 9/25, Batch 10, Cost 1.6171283508251069, Acc 0.718. Time 1.34061861038208\n",
            "Training at Epoch 9/25, Batch 15, Cost 1.6168031372717508, Acc 0.694. Time 1.3401384353637695\n",
            "Training at Epoch 9/25, Batch 20, Cost 1.6248274816784627, Acc 0.7. Time 1.3406813144683838\n",
            "Training at Epoch 9/25, Batch 25, Cost 1.6182125785407964, Acc 0.688. Time 1.3530290126800537\n",
            "Training at Epoch 9/25, Batch 30, Cost 1.6247385489296078, Acc 0.714. Time 1.332845687866211\n",
            "Training at Epoch 9/25, Batch 35, Cost 1.6229335292331872, Acc 0.718. Time 1.3582789897918701\n",
            "Training at Epoch 9/25, Batch 40, Cost 1.6464974336017066, Acc 0.676. Time 1.3316230773925781\n",
            "Training at Epoch 9/25, Batch 45, Cost 1.614626448263328, Acc 0.716. Time 1.3321404457092285\n",
            "Training at Epoch 9/25, Batch 50, Cost 1.6155524003666633, Acc 0.698. Time 1.3300526142120361\n",
            "Training at Epoch 9/25, Batch 55, Cost 1.6332278882150013, Acc 0.744. Time 1.332427740097046\n",
            "Training at Epoch 9/25, Batch 60, Cost 1.6286336534907535, Acc 0.692. Time 1.3321189880371094\n",
            "Training at Epoch 9/25, Batch 65, Cost 1.6237211418264783, Acc 0.688. Time 1.3323476314544678\n",
            "Training at Epoch 9/25, Batch 70, Cost 1.6413781456044982, Acc 0.694. Time 1.3401153087615967\n",
            "Training at Epoch 9/25, Batch 75, Cost 1.6139363335936272, Acc 0.706. Time 1.3335578441619873\n",
            "Training at Epoch 9/25, Batch 80, Cost 1.6190965228897254, Acc 0.752. Time 1.3486402034759521\n",
            "Training at Epoch 9/25, Batch 85, Cost 1.6174045475042875, Acc 0.724. Time 1.3305778503417969\n",
            "Training at Epoch 9/25, Batch 90, Cost 1.6258020226050582, Acc 0.7. Time 1.3323132991790771\n",
            "Training at Epoch 9/25, Batch 95, Cost 1.6411238099155168, Acc 0.662. Time 1.330073595046997\n",
            "Training at Epoch 9/25, Batch 100, Cost 1.6396411014516723, Acc 0.63. Time 1.332956075668335\n",
            "Training at Epoch 9/25, Batch 105, Cost 1.6082605505701966, Acc 0.69. Time 1.336397409439087\n",
            "Training at Epoch 9/25, Batch 110, Cost 1.6225389236695336, Acc 0.694. Time 1.331315517425537\n",
            "Training at Epoch 9/25, Batch 115, Cost 1.6233528224478764, Acc 0.71. Time 1.3478622436523438\n",
            "Training at Epoch 9/25, Batch 120, Cost 1.629982416007559, Acc 0.666. Time 1.3298752307891846\n",
            "Testing at Epoch 9/25, Batch 5, Cost 1.6239817042307054, Acc 0.692. Time 0.3376452922821045\n",
            "Testing at Epoch 9/25, Batch 10, Cost 1.6135795415684315, Acc 0.71. Time 0.33801913261413574\n",
            "Testing at Epoch 9/25, Batch 15, Cost 1.614840984943125, Acc 0.72. Time 0.3425135612487793\n",
            "Testing at Epoch 9/25, Batch 20, Cost 1.6228312579931838, Acc 0.728. Time 0.3359260559082031\n",
            "......\n",
            "Epoch 9/25, Train: Cost 1.62399111963947, Acc 0.6995166666666667\n",
            "Epoch 9/25, Test: Cost 1.618681292259928, Acc 0.728. Time 180.24112057685852\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 10/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 10/25, Batch 5, Cost 1.628842701343368, Acc 0.678. Time 1.3328261375427246\n",
            "Training at Epoch 10/25, Batch 10, Cost 1.6128769533438692, Acc 0.704. Time 1.332338571548462\n",
            "Training at Epoch 10/25, Batch 15, Cost 1.614383923283252, Acc 0.718. Time 1.3332314491271973\n",
            "Training at Epoch 10/25, Batch 20, Cost 1.6401450059429876, Acc 0.66. Time 1.3364133834838867\n",
            "Training at Epoch 10/25, Batch 25, Cost 1.6128020350126626, Acc 0.696. Time 1.3466460704803467\n",
            "Training at Epoch 10/25, Batch 30, Cost 1.6081625425729773, Acc 0.75. Time 1.3376240730285645\n",
            "Training at Epoch 10/25, Batch 35, Cost 1.6181371628283097, Acc 0.69. Time 1.3375828266143799\n",
            "Training at Epoch 10/25, Batch 40, Cost 1.605442141322434, Acc 0.742. Time 1.3317809104919434\n",
            "Training at Epoch 10/25, Batch 45, Cost 1.6237669105246275, Acc 0.716. Time 1.3345391750335693\n",
            "Training at Epoch 10/25, Batch 50, Cost 1.611060353253121, Acc 0.71. Time 1.3329660892486572\n",
            "Training at Epoch 10/25, Batch 55, Cost 1.6224071400260225, Acc 0.692. Time 1.3307578563690186\n",
            "Training at Epoch 10/25, Batch 60, Cost 1.626979996182581, Acc 0.68. Time 1.3334386348724365\n",
            "Training at Epoch 10/25, Batch 65, Cost 1.617887759076806, Acc 0.704. Time 1.334507703781128\n",
            "Training at Epoch 10/25, Batch 70, Cost 1.6260375342947908, Acc 0.684. Time 1.3474996089935303\n",
            "Training at Epoch 10/25, Batch 75, Cost 1.6229139649597195, Acc 0.72. Time 1.3284733295440674\n",
            "Training at Epoch 10/25, Batch 80, Cost 1.6184867595493024, Acc 0.72. Time 1.3408691883087158\n",
            "Training at Epoch 10/25, Batch 85, Cost 1.6267914731610664, Acc 0.702. Time 1.3350887298583984\n",
            "Training at Epoch 10/25, Batch 90, Cost 1.618135461943464, Acc 0.698. Time 1.3433144092559814\n",
            "Training at Epoch 10/25, Batch 95, Cost 1.6223898653252065, Acc 0.702. Time 1.3344361782073975\n",
            "Training at Epoch 10/25, Batch 100, Cost 1.6116690628836174, Acc 0.688. Time 1.3380889892578125\n",
            "Training at Epoch 10/25, Batch 105, Cost 1.625694438493284, Acc 0.728. Time 1.330305814743042\n",
            "Training at Epoch 10/25, Batch 110, Cost 1.6087975151829124, Acc 0.724. Time 1.3302254676818848\n",
            "Training at Epoch 10/25, Batch 115, Cost 1.6200018249182897, Acc 0.698. Time 1.3527464866638184\n",
            "Training at Epoch 10/25, Batch 120, Cost 1.61703678361393, Acc 0.704. Time 1.333298683166504\n",
            "Testing at Epoch 10/25, Batch 5, Cost 1.6069858806052906, Acc 0.706. Time 0.3387882709503174\n",
            "Testing at Epoch 10/25, Batch 10, Cost 1.6013687772162655, Acc 0.726. Time 0.33571958541870117\n",
            "Testing at Epoch 10/25, Batch 15, Cost 1.6380419187021185, Acc 0.67. Time 0.3410320281982422\n",
            "Testing at Epoch 10/25, Batch 20, Cost 1.6202369514573225, Acc 0.704. Time 0.3375234603881836\n",
            "......\n",
            "Epoch 10/25, Train: Cost 1.620978411240821, Acc 0.7004833333333332\n",
            "Epoch 10/25, Test: Cost 1.6144197841014747, Acc 0.704. Time 180.32353496551514\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 11/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 11/25, Batch 5, Cost 1.6124089725680375, Acc 0.702. Time 1.3411633968353271\n",
            "Training at Epoch 11/25, Batch 10, Cost 1.604236487460587, Acc 0.7. Time 1.343984842300415\n",
            "Training at Epoch 11/25, Batch 15, Cost 1.6348489966029558, Acc 0.694. Time 1.3554904460906982\n",
            "Training at Epoch 11/25, Batch 20, Cost 1.6287144051519522, Acc 0.716. Time 1.3450400829315186\n",
            "Training at Epoch 11/25, Batch 25, Cost 1.6223109198700565, Acc 0.698. Time 1.3621282577514648\n",
            "Training at Epoch 11/25, Batch 30, Cost 1.6188986497678783, Acc 0.71. Time 1.3407618999481201\n",
            "Training at Epoch 11/25, Batch 35, Cost 1.6288130690183027, Acc 0.712. Time 1.3349900245666504\n",
            "Training at Epoch 11/25, Batch 40, Cost 1.6407677473306732, Acc 0.658. Time 1.3488812446594238\n",
            "Training at Epoch 11/25, Batch 45, Cost 1.605340861439548, Acc 0.72. Time 1.3431000709533691\n",
            "Training at Epoch 11/25, Batch 50, Cost 1.611414116624944, Acc 0.71. Time 1.350287914276123\n",
            "Training at Epoch 11/25, Batch 55, Cost 1.624868296340344, Acc 0.71. Time 1.3470005989074707\n",
            "Training at Epoch 11/25, Batch 60, Cost 1.6133258571212665, Acc 0.676. Time 1.357184886932373\n",
            "Training at Epoch 11/25, Batch 65, Cost 1.5903852256592155, Acc 0.75. Time 1.3448410034179688\n",
            "Training at Epoch 11/25, Batch 70, Cost 1.6109869498505265, Acc 0.706. Time 1.3604259490966797\n",
            "Training at Epoch 11/25, Batch 75, Cost 1.6326202142868762, Acc 0.646. Time 1.346160888671875\n",
            "Training at Epoch 11/25, Batch 80, Cost 1.621766014339485, Acc 0.712. Time 1.345292091369629\n",
            "Training at Epoch 11/25, Batch 85, Cost 1.6113533398070956, Acc 0.69. Time 1.3429102897644043\n",
            "Training at Epoch 11/25, Batch 90, Cost 1.6306081613286043, Acc 0.672. Time 1.3454172611236572\n",
            "Training at Epoch 11/25, Batch 95, Cost 1.5961719356622133, Acc 0.738. Time 1.3579106330871582\n",
            "Training at Epoch 11/25, Batch 100, Cost 1.6126937322947943, Acc 0.706. Time 1.3468644618988037\n",
            "Training at Epoch 11/25, Batch 105, Cost 1.6067239042619963, Acc 0.724. Time 1.3594987392425537\n",
            "Training at Epoch 11/25, Batch 110, Cost 1.6267563807396825, Acc 0.702. Time 1.347614049911499\n",
            "Training at Epoch 11/25, Batch 115, Cost 1.621338339024601, Acc 0.708. Time 1.3486449718475342\n",
            "Training at Epoch 11/25, Batch 120, Cost 1.626312089534952, Acc 0.68. Time 1.348090410232544\n",
            "Testing at Epoch 11/25, Batch 5, Cost 1.6239869623852927, Acc 0.686. Time 0.34067201614379883\n",
            "Testing at Epoch 11/25, Batch 10, Cost 1.6225134741460796, Acc 0.682. Time 0.34314775466918945\n",
            "Testing at Epoch 11/25, Batch 15, Cost 1.6063814599749562, Acc 0.712. Time 0.33975672721862793\n",
            "Testing at Epoch 11/25, Batch 20, Cost 1.6211156839598222, Acc 0.696. Time 0.3403916358947754\n",
            "......\n",
            "Epoch 11/25, Train: Cost 1.6186532165335987, Acc 0.7022499999999999\n",
            "Epoch 11/25, Test: Cost 1.6138329073319782, Acc 0.696. Time 181.63079237937927\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 12/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 12/25, Batch 5, Cost 1.631015431900245, Acc 0.676. Time 1.347965955734253\n",
            "Training at Epoch 12/25, Batch 10, Cost 1.633985349879176, Acc 0.694. Time 1.3447632789611816\n",
            "Training at Epoch 12/25, Batch 15, Cost 1.6207399588070153, Acc 0.708. Time 1.365889072418213\n",
            "Training at Epoch 12/25, Batch 20, Cost 1.6178436198562054, Acc 0.712. Time 1.344040870666504\n",
            "Training at Epoch 12/25, Batch 25, Cost 1.5936023236183314, Acc 0.764. Time 1.3352181911468506\n",
            "Training at Epoch 12/25, Batch 30, Cost 1.6105425180390505, Acc 0.68. Time 1.334101915359497\n",
            "Training at Epoch 12/25, Batch 35, Cost 1.630418063056711, Acc 0.684. Time 1.331512212753296\n",
            "Training at Epoch 12/25, Batch 40, Cost 1.6078606445081216, Acc 0.68. Time 1.329559564590454\n",
            "Training at Epoch 12/25, Batch 45, Cost 1.6278349550799813, Acc 0.676. Time 1.3302371501922607\n",
            "Training at Epoch 12/25, Batch 50, Cost 1.6292651269040976, Acc 0.704. Time 1.3459126949310303\n",
            "Training at Epoch 12/25, Batch 55, Cost 1.609786623947229, Acc 0.73. Time 1.33231782913208\n",
            "Training at Epoch 12/25, Batch 60, Cost 1.6327910434664927, Acc 0.696. Time 1.348705768585205\n",
            "Training at Epoch 12/25, Batch 65, Cost 1.6056537185787199, Acc 0.732. Time 1.3302536010742188\n",
            "Training at Epoch 12/25, Batch 70, Cost 1.6273933312518913, Acc 0.716. Time 1.333019733428955\n",
            "Training at Epoch 12/25, Batch 75, Cost 1.6326967705206925, Acc 0.698. Time 1.3330457210540771\n",
            "Training at Epoch 12/25, Batch 80, Cost 1.6401529340858363, Acc 0.672. Time 1.3270659446716309\n",
            "Training at Epoch 12/25, Batch 85, Cost 1.5924570111039666, Acc 0.74. Time 1.3299708366394043\n",
            "Training at Epoch 12/25, Batch 90, Cost 1.6138756239805592, Acc 0.69. Time 1.3386280536651611\n",
            "Training at Epoch 12/25, Batch 95, Cost 1.5907044400054418, Acc 0.724. Time 1.3477742671966553\n",
            "Training at Epoch 12/25, Batch 100, Cost 1.6028989204188464, Acc 0.706. Time 1.3325655460357666\n",
            "Training at Epoch 12/25, Batch 105, Cost 1.5960669667235379, Acc 0.72. Time 1.3499171733856201\n",
            "Training at Epoch 12/25, Batch 110, Cost 1.6075098471549092, Acc 0.702. Time 1.3332617282867432\n",
            "Training at Epoch 12/25, Batch 115, Cost 1.6329424352159896, Acc 0.712. Time 1.332930326461792\n",
            "Training at Epoch 12/25, Batch 120, Cost 1.610374539305643, Acc 0.724. Time 1.3297531604766846\n",
            "Testing at Epoch 12/25, Batch 5, Cost 1.619490200856621, Acc 0.702. Time 0.3445920944213867\n",
            "Testing at Epoch 12/25, Batch 10, Cost 1.6263400324069839, Acc 0.714. Time 0.33652377128601074\n",
            "Testing at Epoch 12/25, Batch 15, Cost 1.6137449009392044, Acc 0.708. Time 0.3385963439941406\n",
            "Testing at Epoch 12/25, Batch 20, Cost 1.616117992417432, Acc 0.696. Time 0.3419928550720215\n",
            "......\n",
            "Epoch 12/25, Train: Cost 1.6153978863830918, Acc 0.7027166666666667\n",
            "Epoch 12/25, Test: Cost 1.6088922119286895, Acc 0.696. Time 180.34497141838074\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 13/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 13/25, Batch 5, Cost 1.6209401353959245, Acc 0.664. Time 1.3493824005126953\n",
            "Training at Epoch 13/25, Batch 10, Cost 1.6081047676673312, Acc 0.71. Time 1.3396201133728027\n",
            "Training at Epoch 13/25, Batch 15, Cost 1.6200864747238364, Acc 0.688. Time 1.3449549674987793\n",
            "Training at Epoch 13/25, Batch 20, Cost 1.6015833978490237, Acc 0.692. Time 1.346592903137207\n",
            "Training at Epoch 13/25, Batch 25, Cost 1.6316655551284283, Acc 0.696. Time 1.3441896438598633\n",
            "Training at Epoch 13/25, Batch 30, Cost 1.6119788834608169, Acc 0.716. Time 1.344879388809204\n",
            "Training at Epoch 13/25, Batch 35, Cost 1.6103199049054735, Acc 0.698. Time 1.3447997570037842\n",
            "Training at Epoch 13/25, Batch 40, Cost 1.6079768298961261, Acc 0.706. Time 1.3535830974578857\n",
            "Training at Epoch 13/25, Batch 45, Cost 1.6015271745199766, Acc 0.726. Time 1.3479440212249756\n",
            "Training at Epoch 13/25, Batch 50, Cost 1.6331063712166214, Acc 0.698. Time 1.361051321029663\n",
            "Training at Epoch 13/25, Batch 55, Cost 1.6097484997065983, Acc 0.722. Time 1.3433043956756592\n",
            "Training at Epoch 13/25, Batch 60, Cost 1.6238644162195308, Acc 0.734. Time 1.3420054912567139\n",
            "Training at Epoch 13/25, Batch 65, Cost 1.6296001727441052, Acc 0.7. Time 1.3444113731384277\n",
            "Training at Epoch 13/25, Batch 70, Cost 1.6058334343091598, Acc 0.716. Time 1.3427212238311768\n",
            "Training at Epoch 13/25, Batch 75, Cost 1.6024731541439354, Acc 0.702. Time 1.3471550941467285\n",
            "Training at Epoch 13/25, Batch 80, Cost 1.6056993774875172, Acc 0.714. Time 1.3464024066925049\n",
            "Training at Epoch 13/25, Batch 85, Cost 1.6103351428808141, Acc 0.718. Time 1.3600938320159912\n",
            "Training at Epoch 13/25, Batch 90, Cost 1.6232714748359591, Acc 0.67. Time 1.3458383083343506\n",
            "Training at Epoch 13/25, Batch 95, Cost 1.5984629782724171, Acc 0.694. Time 1.3482635021209717\n",
            "Training at Epoch 13/25, Batch 100, Cost 1.6206813526282495, Acc 0.682. Time 1.3433010578155518\n",
            "Training at Epoch 13/25, Batch 105, Cost 1.5974111307910888, Acc 0.696. Time 1.3432514667510986\n",
            "Training at Epoch 13/25, Batch 110, Cost 1.6203313992679427, Acc 0.684. Time 1.3428072929382324\n",
            "Training at Epoch 13/25, Batch 115, Cost 1.5886336005209745, Acc 0.734. Time 1.3432714939117432\n",
            "Training at Epoch 13/25, Batch 120, Cost 1.6203364112757581, Acc 0.702. Time 1.3583505153656006\n",
            "Testing at Epoch 13/25, Batch 5, Cost 1.603606763019167, Acc 0.72. Time 0.34085845947265625\n",
            "Testing at Epoch 13/25, Batch 10, Cost 1.6212751230451579, Acc 0.688. Time 0.3379371166229248\n",
            "Testing at Epoch 13/25, Batch 15, Cost 1.6156990608989072, Acc 0.668. Time 0.33986496925354004\n",
            "Testing at Epoch 13/25, Batch 20, Cost 1.62633631745515, Acc 0.686. Time 0.3380305767059326\n",
            "......\n",
            "Epoch 13/25, Train: Cost 1.6130519464399562, Acc 0.70345\n",
            "Epoch 13/25, Test: Cost 1.6083306220806837, Acc 0.686. Time 181.4192144870758\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 14/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 14/25, Batch 5, Cost 1.6083270914955887, Acc 0.688. Time 1.337651014328003\n",
            "Training at Epoch 14/25, Batch 10, Cost 1.5958120304141823, Acc 0.746. Time 1.33990478515625\n",
            "Training at Epoch 14/25, Batch 15, Cost 1.6085248894581294, Acc 0.686. Time 1.3359384536743164\n",
            "Training at Epoch 14/25, Batch 20, Cost 1.613510483908096, Acc 0.706. Time 1.3463456630706787\n",
            "Training at Epoch 14/25, Batch 25, Cost 1.5972614145196251, Acc 0.746. Time 1.3382585048675537\n",
            "Training at Epoch 14/25, Batch 30, Cost 1.5950709099753815, Acc 0.744. Time 1.3407070636749268\n",
            "Training at Epoch 14/25, Batch 35, Cost 1.605797830941831, Acc 0.7. Time 1.3345141410827637\n",
            "Training at Epoch 14/25, Batch 40, Cost 1.6104108173467178, Acc 0.698. Time 1.3482027053833008\n",
            "Training at Epoch 14/25, Batch 45, Cost 1.6294272484633985, Acc 0.638. Time 1.3317546844482422\n",
            "Training at Epoch 14/25, Batch 50, Cost 1.6139406334939632, Acc 0.694. Time 1.344273567199707\n",
            "Training at Epoch 14/25, Batch 55, Cost 1.613765243780558, Acc 0.712. Time 1.3339886665344238\n",
            "Training at Epoch 14/25, Batch 60, Cost 1.6176240170180258, Acc 0.648. Time 1.3375604152679443\n",
            "Training at Epoch 14/25, Batch 65, Cost 1.6326204341574948, Acc 0.682. Time 1.3349640369415283\n",
            "Training at Epoch 14/25, Batch 70, Cost 1.6090542474852199, Acc 0.7. Time 1.331188440322876\n",
            "Training at Epoch 14/25, Batch 75, Cost 1.6109619504189285, Acc 0.682. Time 1.3357105255126953\n",
            "Training at Epoch 14/25, Batch 80, Cost 1.6255968290801068, Acc 0.668. Time 1.3318943977355957\n",
            "Training at Epoch 14/25, Batch 85, Cost 1.6064983102897872, Acc 0.68. Time 1.3544509410858154\n",
            "Training at Epoch 14/25, Batch 90, Cost 1.6290439285951919, Acc 0.672. Time 1.3332221508026123\n",
            "Training at Epoch 14/25, Batch 95, Cost 1.5840537351363861, Acc 0.73. Time 1.3497648239135742\n",
            "Training at Epoch 14/25, Batch 100, Cost 1.6078328798491224, Acc 0.722. Time 1.3351953029632568\n",
            "Training at Epoch 14/25, Batch 105, Cost 1.6070250679385167, Acc 0.718. Time 1.335639238357544\n",
            "Training at Epoch 14/25, Batch 110, Cost 1.5985137182904956, Acc 0.724. Time 1.328568696975708\n",
            "Training at Epoch 14/25, Batch 115, Cost 1.6203883524039076, Acc 0.672. Time 1.334726333618164\n",
            "Training at Epoch 14/25, Batch 120, Cost 1.6194910747803022, Acc 0.704. Time 1.3377199172973633\n",
            "Testing at Epoch 14/25, Batch 5, Cost 1.6058221018854542, Acc 0.698. Time 0.3414766788482666\n",
            "Testing at Epoch 14/25, Batch 10, Cost 1.5935130417258188, Acc 0.72. Time 0.3374340534210205\n",
            "Testing at Epoch 14/25, Batch 15, Cost 1.6062782637693596, Acc 0.688. Time 0.33942079544067383\n",
            "Testing at Epoch 14/25, Batch 20, Cost 1.6005335602704343, Acc 0.68. Time 0.33809971809387207\n",
            "......\n",
            "Epoch 14/25, Train: Cost 1.6109240575514507, Acc 0.70385\n",
            "Epoch 14/25, Test: Cost 1.6044221941117904, Acc 0.68. Time 180.705157995224\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 15/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 15/25, Batch 5, Cost 1.6120640572565479, Acc 0.708. Time 1.3485827445983887\n",
            "Training at Epoch 15/25, Batch 10, Cost 1.6101064857889915, Acc 0.694. Time 1.3401353359222412\n",
            "Training at Epoch 15/25, Batch 15, Cost 1.6066620730640278, Acc 0.724. Time 1.3368682861328125\n",
            "Training at Epoch 15/25, Batch 20, Cost 1.6162122740571856, Acc 0.694. Time 1.3404581546783447\n",
            "Training at Epoch 15/25, Batch 25, Cost 1.6127535209036579, Acc 0.722. Time 1.3392906188964844\n",
            "Training at Epoch 15/25, Batch 30, Cost 1.6078777201294792, Acc 0.706. Time 1.3382811546325684\n",
            "Training at Epoch 15/25, Batch 35, Cost 1.6146295944015832, Acc 0.71. Time 1.3413689136505127\n",
            "Training at Epoch 15/25, Batch 40, Cost 1.6287122535584613, Acc 0.638. Time 1.3385376930236816\n",
            "Training at Epoch 15/25, Batch 45, Cost 1.6208964501621506, Acc 0.692. Time 1.3419601917266846\n",
            "Training at Epoch 15/25, Batch 50, Cost 1.6310894994659495, Acc 0.682. Time 1.352144718170166\n",
            "Training at Epoch 15/25, Batch 55, Cost 1.613254360676981, Acc 0.706. Time 1.3402564525604248\n",
            "Training at Epoch 15/25, Batch 60, Cost 1.6001364234794366, Acc 0.742. Time 1.3554933071136475\n",
            "Training at Epoch 15/25, Batch 65, Cost 1.6297089751915441, Acc 0.702. Time 1.3398005962371826\n",
            "Training at Epoch 15/25, Batch 70, Cost 1.6079019776698569, Acc 0.698. Time 1.3376619815826416\n",
            "Training at Epoch 15/25, Batch 75, Cost 1.6347884908582084, Acc 0.704. Time 1.3355059623718262\n",
            "Training at Epoch 15/25, Batch 80, Cost 1.595724618816486, Acc 0.724. Time 1.3366639614105225\n",
            "Training at Epoch 15/25, Batch 85, Cost 1.6159753804699735, Acc 0.716. Time 1.3539700508117676\n",
            "Training at Epoch 15/25, Batch 90, Cost 1.5954031966724083, Acc 0.716. Time 1.3383572101593018\n",
            "Training at Epoch 15/25, Batch 95, Cost 1.6000354552016027, Acc 0.724. Time 1.3540492057800293\n",
            "Training at Epoch 15/25, Batch 100, Cost 1.6234839628733335, Acc 0.7. Time 1.3393971920013428\n",
            "Training at Epoch 15/25, Batch 105, Cost 1.5999338581894513, Acc 0.718. Time 1.3376171588897705\n",
            "Training at Epoch 15/25, Batch 110, Cost 1.6214797140165136, Acc 0.73. Time 1.3356208801269531\n",
            "Training at Epoch 15/25, Batch 115, Cost 1.624738444556332, Acc 0.672. Time 1.3356497287750244\n",
            "Training at Epoch 15/25, Batch 120, Cost 1.599087817051693, Acc 0.718. Time 1.3425531387329102\n",
            "Testing at Epoch 15/25, Batch 5, Cost 1.6186413857576525, Acc 0.704. Time 0.34197092056274414\n",
            "Testing at Epoch 15/25, Batch 10, Cost 1.6011559836873364, Acc 0.732. Time 0.3374485969543457\n",
            "Testing at Epoch 15/25, Batch 15, Cost 1.5921631097594022, Acc 0.714. Time 0.33809804916381836\n",
            "Testing at Epoch 15/25, Batch 20, Cost 1.6065282206390503, Acc 0.694. Time 0.33845090866088867\n",
            "......\n",
            "Epoch 15/25, Train: Cost 1.6098831085074408, Acc 0.7041333333333333\n",
            "Epoch 15/25, Test: Cost 1.6039174985123608, Acc 0.694. Time 180.96577644348145\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 16/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 16/25, Batch 5, Cost 1.6157191985946706, Acc 0.688. Time 1.3565740585327148\n",
            "Training at Epoch 16/25, Batch 10, Cost 1.6091512582221754, Acc 0.664. Time 1.344407558441162\n",
            "Training at Epoch 16/25, Batch 15, Cost 1.6110824662685432, Acc 0.694. Time 1.339233636856079\n",
            "Training at Epoch 16/25, Batch 20, Cost 1.6180996571896171, Acc 0.678. Time 1.3446414470672607\n",
            "Training at Epoch 16/25, Batch 25, Cost 1.6057043014480543, Acc 0.708. Time 1.3457036018371582\n",
            "Training at Epoch 16/25, Batch 30, Cost 1.589721837263712, Acc 0.728. Time 1.3599510192871094\n",
            "Training at Epoch 16/25, Batch 35, Cost 1.5993089347642802, Acc 0.694. Time 1.3447940349578857\n",
            "Training at Epoch 16/25, Batch 40, Cost 1.6102317321462987, Acc 0.72. Time 1.357088565826416\n",
            "Training at Epoch 16/25, Batch 45, Cost 1.602863520754903, Acc 0.718. Time 1.342223882675171\n",
            "Training at Epoch 16/25, Batch 50, Cost 1.6062273446163073, Acc 0.692. Time 1.3630917072296143\n",
            "Training at Epoch 16/25, Batch 55, Cost 1.613137363925365, Acc 0.676. Time 1.3434059619903564\n",
            "Training at Epoch 16/25, Batch 60, Cost 1.6098072004484332, Acc 0.724. Time 1.345750331878662\n",
            "Training at Epoch 16/25, Batch 65, Cost 1.6106824543916012, Acc 0.696. Time 1.3434357643127441\n",
            "Training at Epoch 16/25, Batch 70, Cost 1.6032115465310348, Acc 0.722. Time 1.3423702716827393\n",
            "Training at Epoch 16/25, Batch 75, Cost 1.621465851805152, Acc 0.69. Time 1.3438618183135986\n",
            "Training at Epoch 16/25, Batch 80, Cost 1.6213279900742605, Acc 0.69. Time 1.343454360961914\n",
            "Training at Epoch 16/25, Batch 85, Cost 1.597766798077695, Acc 0.688. Time 1.357797384262085\n",
            "Training at Epoch 16/25, Batch 90, Cost 1.6023107908912109, Acc 0.716. Time 1.3456683158874512\n",
            "Training at Epoch 16/25, Batch 95, Cost 1.6081716650180085, Acc 0.694. Time 1.355109691619873\n",
            "Training at Epoch 16/25, Batch 100, Cost 1.6026352042336167, Acc 0.696. Time 1.3427248001098633\n",
            "Training at Epoch 16/25, Batch 105, Cost 1.614182320303066, Acc 0.692. Time 1.3405952453613281\n",
            "Training at Epoch 16/25, Batch 110, Cost 1.6026916065221166, Acc 0.684. Time 1.3470995426177979\n",
            "Training at Epoch 16/25, Batch 115, Cost 1.6037895332754641, Acc 0.692. Time 1.3453853130340576\n",
            "Training at Epoch 16/25, Batch 120, Cost 1.5928069775520761, Acc 0.736. Time 1.355445146560669\n",
            "Testing at Epoch 16/25, Batch 5, Cost 1.5888927887786584, Acc 0.736. Time 0.34196901321411133\n",
            "Testing at Epoch 16/25, Batch 10, Cost 1.590979324704182, Acc 0.698. Time 0.3402082920074463\n",
            "Testing at Epoch 16/25, Batch 15, Cost 1.600317456603668, Acc 0.73. Time 0.3386514186859131\n",
            "Testing at Epoch 16/25, Batch 20, Cost 1.6061015803339582, Acc 0.678. Time 0.34023237228393555\n",
            "......\n",
            "Epoch 16/25, Train: Cost 1.6073228308892094, Acc 0.7050666666666666\n",
            "Epoch 16/25, Test: Cost 1.601463267453467, Acc 0.678. Time 181.63971996307373\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 17/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 17/25, Batch 5, Cost 1.6074046875903183, Acc 0.71. Time 1.3442106246948242\n",
            "Training at Epoch 17/25, Batch 10, Cost 1.5865453297848235, Acc 0.72. Time 1.3424718379974365\n",
            "Training at Epoch 17/25, Batch 15, Cost 1.5968958601799939, Acc 0.712. Time 1.3412830829620361\n",
            "Training at Epoch 17/25, Batch 20, Cost 1.6109714820593968, Acc 0.686. Time 1.3458189964294434\n",
            "Training at Epoch 17/25, Batch 25, Cost 1.6004109612198483, Acc 0.714. Time 1.3396682739257812\n",
            "Training at Epoch 17/25, Batch 30, Cost 1.5959126066042248, Acc 0.73. Time 1.346606969833374\n",
            "Training at Epoch 17/25, Batch 35, Cost 1.6067970034193113, Acc 0.698. Time 1.347825527191162\n",
            "Training at Epoch 17/25, Batch 40, Cost 1.5976964114764123, Acc 0.71. Time 1.3565492630004883\n",
            "Training at Epoch 17/25, Batch 45, Cost 1.620806884418483, Acc 0.7. Time 1.3424005508422852\n",
            "Training at Epoch 17/25, Batch 50, Cost 1.5974126642066042, Acc 0.73. Time 1.349707841873169\n",
            "Training at Epoch 17/25, Batch 55, Cost 1.5979115940926862, Acc 0.71. Time 1.3416194915771484\n",
            "Training at Epoch 17/25, Batch 60, Cost 1.6014798625163822, Acc 0.676. Time 1.3441355228424072\n",
            "Training at Epoch 17/25, Batch 65, Cost 1.611719085080234, Acc 0.728. Time 1.346088171005249\n",
            "Training at Epoch 17/25, Batch 70, Cost 1.6018618408401804, Acc 0.7. Time 1.3458685874938965\n",
            "Training at Epoch 17/25, Batch 75, Cost 1.6033368743352965, Acc 0.734. Time 1.3563387393951416\n",
            "Training at Epoch 17/25, Batch 80, Cost 1.6001346668293404, Acc 0.75. Time 1.3424711227416992\n",
            "Training at Epoch 17/25, Batch 85, Cost 1.6136605820955923, Acc 0.706. Time 1.3572359085083008\n",
            "Training at Epoch 17/25, Batch 90, Cost 1.598555131941331, Acc 0.704. Time 1.3440022468566895\n",
            "Training at Epoch 17/25, Batch 95, Cost 1.5999943565634471, Acc 0.724. Time 1.3459982872009277\n",
            "Training at Epoch 17/25, Batch 100, Cost 1.5975438939467113, Acc 0.684. Time 1.3423924446105957\n",
            "Training at Epoch 17/25, Batch 105, Cost 1.6023086986828643, Acc 0.72. Time 1.342991828918457\n",
            "Training at Epoch 17/25, Batch 110, Cost 1.5872988045570295, Acc 0.718. Time 1.342031717300415\n",
            "Training at Epoch 17/25, Batch 115, Cost 1.6019827586541193, Acc 0.734. Time 1.34328031539917\n",
            "Training at Epoch 17/25, Batch 120, Cost 1.6261329070022856, Acc 0.678. Time 1.3621976375579834\n",
            "Testing at Epoch 17/25, Batch 5, Cost 1.5982400352550272, Acc 0.692. Time 0.33771204948425293\n",
            "Testing at Epoch 17/25, Batch 10, Cost 1.6065555176064303, Acc 0.68. Time 0.33781862258911133\n",
            "Testing at Epoch 17/25, Batch 15, Cost 1.5990497784215072, Acc 0.742. Time 0.34053707122802734\n",
            "Testing at Epoch 17/25, Batch 20, Cost 1.6104460941883223, Acc 0.702. Time 0.34064817428588867\n",
            "......\n",
            "Epoch 17/25, Train: Cost 1.6052820810550656, Acc 0.7053666666666667\n",
            "Epoch 17/25, Test: Cost 1.5997434578260101, Acc 0.702. Time 181.06017994880676\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 18/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 18/25, Batch 5, Cost 1.609252456414442, Acc 0.684. Time 1.3381712436676025\n",
            "Training at Epoch 18/25, Batch 10, Cost 1.614572365951034, Acc 0.666. Time 1.33720064163208\n",
            "Training at Epoch 18/25, Batch 15, Cost 1.592493250426973, Acc 0.726. Time 1.339198112487793\n",
            "Training at Epoch 18/25, Batch 20, Cost 1.5981889684562607, Acc 0.7. Time 1.3463406562805176\n",
            "Training at Epoch 18/25, Batch 25, Cost 1.5986139561721284, Acc 0.686. Time 1.3429584503173828\n",
            "Training at Epoch 18/25, Batch 30, Cost 1.5848302395998881, Acc 0.712. Time 1.3529744148254395\n",
            "Training at Epoch 18/25, Batch 35, Cost 1.5873565125276194, Acc 0.756. Time 1.3426036834716797\n",
            "Training at Epoch 18/25, Batch 40, Cost 1.6207169668812236, Acc 0.7. Time 1.3449287414550781\n",
            "Training at Epoch 18/25, Batch 45, Cost 1.603036144435278, Acc 0.722. Time 1.3480877876281738\n",
            "Training at Epoch 18/25, Batch 50, Cost 1.6071214361825517, Acc 0.664. Time 1.3409371376037598\n",
            "Training at Epoch 18/25, Batch 55, Cost 1.6038053523901965, Acc 0.716. Time 1.3433003425598145\n",
            "Training at Epoch 18/25, Batch 60, Cost 1.6205561763785057, Acc 0.712. Time 1.3356871604919434\n",
            "Training at Epoch 18/25, Batch 65, Cost 1.600505469744869, Acc 0.704. Time 1.349877119064331\n",
            "Training at Epoch 18/25, Batch 70, Cost 1.599740054682152, Acc 0.722. Time 1.3366339206695557\n",
            "Training at Epoch 18/25, Batch 75, Cost 1.6043909879758418, Acc 0.672. Time 1.354684591293335\n",
            "Training at Epoch 18/25, Batch 80, Cost 1.6070185140963715, Acc 0.708. Time 1.342191219329834\n",
            "Training at Epoch 18/25, Batch 85, Cost 1.5986302706122801, Acc 0.684. Time 1.3369104862213135\n",
            "Training at Epoch 18/25, Batch 90, Cost 1.6129762329697857, Acc 0.698. Time 1.3386147022247314\n",
            "Training at Epoch 18/25, Batch 95, Cost 1.6064562487677028, Acc 0.73. Time 1.3415298461914062\n",
            "Training at Epoch 18/25, Batch 100, Cost 1.5893165653608787, Acc 0.704. Time 1.3434209823608398\n",
            "Training at Epoch 18/25, Batch 105, Cost 1.5999159761274282, Acc 0.722. Time 1.3384881019592285\n",
            "Training at Epoch 18/25, Batch 110, Cost 1.5980262970025252, Acc 0.696. Time 1.3493139743804932\n",
            "Training at Epoch 18/25, Batch 115, Cost 1.5981321428968898, Acc 0.724. Time 1.338515043258667\n",
            "Training at Epoch 18/25, Batch 120, Cost 1.6141867699447348, Acc 0.666. Time 1.3411729335784912\n",
            "Testing at Epoch 18/25, Batch 5, Cost 1.575456117562751, Acc 0.734. Time 0.3389129638671875\n",
            "Testing at Epoch 18/25, Batch 10, Cost 1.6109058870597126, Acc 0.716. Time 0.3364725112915039\n",
            "Testing at Epoch 18/25, Batch 15, Cost 1.5986560504948641, Acc 0.71. Time 0.33718132972717285\n",
            "Testing at Epoch 18/25, Batch 20, Cost 1.5991457428793898, Acc 0.682. Time 0.33853816986083984\n",
            "......\n",
            "Epoch 18/25, Train: Cost 1.6045125478580269, Acc 0.7056333333333333\n",
            "Epoch 18/25, Test: Cost 1.5996409566711216, Acc 0.682. Time 180.75329637527466\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 19/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 19/25, Batch 5, Cost 1.6012742277499437, Acc 0.712. Time 1.3395278453826904\n",
            "Training at Epoch 19/25, Batch 10, Cost 1.5931984330132294, Acc 0.71. Time 1.3540196418762207\n",
            "Training at Epoch 19/25, Batch 15, Cost 1.6008998303919204, Acc 0.742. Time 1.346667766571045\n",
            "Training at Epoch 19/25, Batch 20, Cost 1.6190892433970583, Acc 0.708. Time 1.357071876525879\n",
            "Training at Epoch 19/25, Batch 25, Cost 1.6088618753177686, Acc 0.694. Time 1.3451621532440186\n",
            "Training at Epoch 19/25, Batch 30, Cost 1.5935250680791577, Acc 0.682. Time 1.3441648483276367\n",
            "Training at Epoch 19/25, Batch 35, Cost 1.585448715529018, Acc 0.746. Time 1.3450274467468262\n",
            "Training at Epoch 19/25, Batch 40, Cost 1.6009003123262995, Acc 0.722. Time 1.3433992862701416\n",
            "Training at Epoch 19/25, Batch 45, Cost 1.6071709630621953, Acc 0.688. Time 1.3450627326965332\n",
            "Training at Epoch 19/25, Batch 50, Cost 1.61748167350853, Acc 0.694. Time 1.3460454940795898\n",
            "Training at Epoch 19/25, Batch 55, Cost 1.6023455860281093, Acc 0.724. Time 1.357954978942871\n",
            "Training at Epoch 19/25, Batch 60, Cost 1.6199311873751416, Acc 0.726. Time 1.3443970680236816\n",
            "Training at Epoch 19/25, Batch 65, Cost 1.6136011947624638, Acc 0.686. Time 1.3594963550567627\n",
            "Training at Epoch 19/25, Batch 70, Cost 1.5940437266379688, Acc 0.72. Time 1.343226432800293\n",
            "Training at Epoch 19/25, Batch 75, Cost 1.6018543840277109, Acc 0.738. Time 1.343245506286621\n",
            "Training at Epoch 19/25, Batch 80, Cost 1.5938138565743372, Acc 0.692. Time 1.3434185981750488\n",
            "Training at Epoch 19/25, Batch 85, Cost 1.5949210728000587, Acc 0.694. Time 1.3412854671478271\n",
            "Training at Epoch 19/25, Batch 90, Cost 1.597724098215033, Acc 0.714. Time 1.3470818996429443\n",
            "Training at Epoch 19/25, Batch 95, Cost 1.576064701717227, Acc 0.724. Time 1.3411271572113037\n",
            "Training at Epoch 19/25, Batch 100, Cost 1.5816402954096702, Acc 0.716. Time 1.3535711765289307\n",
            "Training at Epoch 19/25, Batch 105, Cost 1.5946598438433643, Acc 0.714. Time 1.3422966003417969\n",
            "Training at Epoch 19/25, Batch 110, Cost 1.6053175241421604, Acc 0.714. Time 1.345566987991333\n",
            "Training at Epoch 19/25, Batch 115, Cost 1.5959838396598673, Acc 0.69. Time 1.3442316055297852\n",
            "Training at Epoch 19/25, Batch 120, Cost 1.6086803552906577, Acc 0.708. Time 1.343554973602295\n",
            "Testing at Epoch 19/25, Batch 5, Cost 1.5842101719354629, Acc 0.742. Time 0.3415188789367676\n",
            "Testing at Epoch 19/25, Batch 10, Cost 1.568624432446608, Acc 0.778. Time 0.3376917839050293\n",
            "Testing at Epoch 19/25, Batch 15, Cost 1.59560873632092, Acc 0.7. Time 0.34078454971313477\n",
            "Testing at Epoch 19/25, Batch 20, Cost 1.6158974270468174, Acc 0.674. Time 0.3442234992980957\n",
            "......\n",
            "Epoch 19/25, Train: Cost 1.603325435637146, Acc 0.70645\n",
            "Epoch 19/25, Test: Cost 1.5976731125334611, Acc 0.674. Time 181.3008804321289\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 20/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 20/25, Batch 5, Cost 1.5897264478915205, Acc 0.722. Time 1.343902349472046\n",
            "Training at Epoch 20/25, Batch 10, Cost 1.5889936105267446, Acc 0.702. Time 1.358025074005127\n",
            "Training at Epoch 20/25, Batch 15, Cost 1.6047636089215684, Acc 0.712. Time 1.3417935371398926\n",
            "Training at Epoch 20/25, Batch 20, Cost 1.6113042079661113, Acc 0.69. Time 1.3455984592437744\n",
            "Training at Epoch 20/25, Batch 25, Cost 1.6163811354968702, Acc 0.692. Time 1.3461029529571533\n",
            "Training at Epoch 20/25, Batch 30, Cost 1.6110199651307173, Acc 0.694. Time 1.341569185256958\n",
            "Training at Epoch 20/25, Batch 35, Cost 1.6100358895288196, Acc 0.678. Time 1.342707872390747\n",
            "Training at Epoch 20/25, Batch 40, Cost 1.6094012230454073, Acc 0.722. Time 1.340291976928711\n",
            "Training at Epoch 20/25, Batch 45, Cost 1.5879920856387533, Acc 0.686. Time 1.3566842079162598\n",
            "Training at Epoch 20/25, Batch 50, Cost 1.599012317468622, Acc 0.734. Time 1.342604398727417\n",
            "Training at Epoch 20/25, Batch 55, Cost 1.5994262379896735, Acc 0.686. Time 1.3580002784729004\n",
            "Training at Epoch 20/25, Batch 60, Cost 1.590064867135611, Acc 0.726. Time 1.3577401638031006\n",
            "Training at Epoch 20/25, Batch 65, Cost 1.5979948096885739, Acc 0.696. Time 1.344982624053955\n",
            "Training at Epoch 20/25, Batch 70, Cost 1.6251140909392037, Acc 0.674. Time 1.344973087310791\n",
            "Training at Epoch 20/25, Batch 75, Cost 1.613650298952274, Acc 0.7. Time 1.3430712223052979\n",
            "Training at Epoch 20/25, Batch 80, Cost 1.6102165660765542, Acc 0.706. Time 1.3436665534973145\n",
            "Training at Epoch 20/25, Batch 85, Cost 1.6009988761532445, Acc 0.694. Time 1.3446526527404785\n",
            "Training at Epoch 20/25, Batch 90, Cost 1.5823100880952041, Acc 0.718. Time 1.360396385192871\n",
            "Training at Epoch 20/25, Batch 95, Cost 1.6081546500808113, Acc 0.72. Time 1.346710205078125\n",
            "Training at Epoch 20/25, Batch 100, Cost 1.5983552773378515, Acc 0.684. Time 1.3470425605773926\n",
            "Training at Epoch 20/25, Batch 105, Cost 1.605965270803009, Acc 0.676. Time 1.3401696681976318\n",
            "Training at Epoch 20/25, Batch 110, Cost 1.607989771795125, Acc 0.642. Time 1.3463096618652344\n",
            "Training at Epoch 20/25, Batch 115, Cost 1.6038551629293898, Acc 0.684. Time 1.340895175933838\n",
            "Training at Epoch 20/25, Batch 120, Cost 1.6018256115374572, Acc 0.678. Time 1.34256911277771\n",
            "Testing at Epoch 20/25, Batch 5, Cost 1.604362343866277, Acc 0.72. Time 0.33875274658203125\n",
            "Testing at Epoch 20/25, Batch 10, Cost 1.6025873290193997, Acc 0.712. Time 0.33963584899902344\n",
            "Testing at Epoch 20/25, Batch 15, Cost 1.597797125649235, Acc 0.732. Time 0.3391716480255127\n",
            "Testing at Epoch 20/25, Batch 20, Cost 1.6048689744892233, Acc 0.684. Time 0.345844030380249\n",
            "......\n",
            "Epoch 20/25, Train: Cost 1.6016805548682431, Acc 0.7062666666666666\n",
            "Epoch 20/25, Test: Cost 1.5958072471763347, Acc 0.684. Time 181.286687374115\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 21/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 21/25, Batch 5, Cost 1.591321459451482, Acc 0.71. Time 1.3420214653015137\n",
            "Training at Epoch 21/25, Batch 10, Cost 1.6099294681113576, Acc 0.694. Time 1.3446269035339355\n",
            "Training at Epoch 21/25, Batch 15, Cost 1.5922956141966513, Acc 0.708. Time 1.3326027393341064\n",
            "Training at Epoch 21/25, Batch 20, Cost 1.6055181866139205, Acc 0.7. Time 1.342503547668457\n",
            "Training at Epoch 21/25, Batch 25, Cost 1.6053104861795602, Acc 0.696. Time 1.341160774230957\n",
            "Training at Epoch 21/25, Batch 30, Cost 1.608992444851985, Acc 0.714. Time 1.3351340293884277\n",
            "Training at Epoch 21/25, Batch 35, Cost 1.616444274421264, Acc 0.702. Time 1.3505322933197021\n",
            "Training at Epoch 21/25, Batch 40, Cost 1.5944470093427507, Acc 0.722. Time 1.338637113571167\n",
            "Training at Epoch 21/25, Batch 45, Cost 1.5953253221956694, Acc 0.716. Time 1.349989891052246\n",
            "Training at Epoch 21/25, Batch 50, Cost 1.6036268072177808, Acc 0.708. Time 1.3381633758544922\n",
            "Training at Epoch 21/25, Batch 55, Cost 1.608768735463493, Acc 0.666. Time 1.3395965099334717\n",
            "Training at Epoch 21/25, Batch 60, Cost 1.5925315131825708, Acc 0.716. Time 1.3358840942382812\n",
            "Training at Epoch 21/25, Batch 65, Cost 1.5938391723685885, Acc 0.71. Time 1.340174913406372\n",
            "Training at Epoch 21/25, Batch 70, Cost 1.5979055976491765, Acc 0.712. Time 1.3540546894073486\n",
            "Training at Epoch 21/25, Batch 75, Cost 1.5894280786760606, Acc 0.694. Time 1.3376514911651611\n",
            "Training at Epoch 21/25, Batch 80, Cost 1.6009107144373471, Acc 0.7. Time 1.3540887832641602\n",
            "Training at Epoch 21/25, Batch 85, Cost 1.5930390033739878, Acc 0.718. Time 1.3393988609313965\n",
            "Training at Epoch 21/25, Batch 90, Cost 1.6223575765399856, Acc 0.672. Time 1.340282917022705\n",
            "Training at Epoch 21/25, Batch 95, Cost 1.6171101180792817, Acc 0.674. Time 1.3422644138336182\n",
            "Training at Epoch 21/25, Batch 100, Cost 1.6066438947128714, Acc 0.708. Time 1.3382606506347656\n",
            "Training at Epoch 21/25, Batch 105, Cost 1.6053889474392882, Acc 0.724. Time 1.3408823013305664\n",
            "Training at Epoch 21/25, Batch 110, Cost 1.599137476317087, Acc 0.68. Time 1.3412961959838867\n",
            "Training at Epoch 21/25, Batch 115, Cost 1.6035420913903278, Acc 0.694. Time 1.3502535820007324\n",
            "Training at Epoch 21/25, Batch 120, Cost 1.5899762174906604, Acc 0.732. Time 1.338735818862915\n",
            "Testing at Epoch 21/25, Batch 5, Cost 1.5853980764607436, Acc 0.714. Time 0.33593058586120605\n",
            "Testing at Epoch 21/25, Batch 10, Cost 1.590224635728834, Acc 0.722. Time 0.33832287788391113\n",
            "Testing at Epoch 21/25, Batch 15, Cost 1.5882858071372008, Acc 0.722. Time 0.34351444244384766\n",
            "Testing at Epoch 21/25, Batch 20, Cost 1.597570178169423, Acc 0.714. Time 0.3368263244628906\n",
            "......\n",
            "Epoch 21/25, Train: Cost 1.6003498089159625, Acc 0.7067\n",
            "Epoch 21/25, Test: Cost 1.5934108181075586, Acc 0.714. Time 180.80982446670532\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 22/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 22/25, Batch 5, Cost 1.5871844649280138, Acc 0.712. Time 1.3403000831604004\n",
            "Training at Epoch 22/25, Batch 10, Cost 1.6049857189278423, Acc 0.706. Time 1.3447084426879883\n",
            "Training at Epoch 22/25, Batch 15, Cost 1.590386331771688, Acc 0.722. Time 1.346440076828003\n",
            "Training at Epoch 22/25, Batch 20, Cost 1.5900843987680815, Acc 0.734. Time 1.3443617820739746\n",
            "Training at Epoch 22/25, Batch 25, Cost 1.616612275586093, Acc 0.69. Time 1.3589591979980469\n",
            "Training at Epoch 22/25, Batch 30, Cost 1.606886155742982, Acc 0.71. Time 1.344348430633545\n",
            "Training at Epoch 22/25, Batch 35, Cost 1.5989061128774165, Acc 0.75. Time 1.3652832508087158\n",
            "Training at Epoch 22/25, Batch 40, Cost 1.604929130689593, Acc 0.72. Time 1.3422951698303223\n",
            "Training at Epoch 22/25, Batch 45, Cost 1.6002381753799262, Acc 0.724. Time 1.3483152389526367\n",
            "Training at Epoch 22/25, Batch 50, Cost 1.5958428928029773, Acc 0.722. Time 1.343712568283081\n",
            "Training at Epoch 22/25, Batch 55, Cost 1.5913176884710978, Acc 0.744. Time 1.3481364250183105\n",
            "Training at Epoch 22/25, Batch 60, Cost 1.5958756878859712, Acc 0.71. Time 1.347644329071045\n",
            "Training at Epoch 22/25, Batch 65, Cost 1.606339210361837, Acc 0.674. Time 1.3428282737731934\n",
            "Training at Epoch 22/25, Batch 70, Cost 1.6108410628952377, Acc 0.734. Time 1.3641266822814941\n",
            "Training at Epoch 22/25, Batch 75, Cost 1.598806440025176, Acc 0.712. Time 1.3372182846069336\n",
            "Training at Epoch 22/25, Batch 80, Cost 1.5977480475635513, Acc 0.712. Time 1.3417713642120361\n",
            "Training at Epoch 22/25, Batch 85, Cost 1.589762131384893, Acc 0.708. Time 1.341980218887329\n",
            "Training at Epoch 22/25, Batch 90, Cost 1.6120509494898818, Acc 0.724. Time 1.3441762924194336\n",
            "Training at Epoch 22/25, Batch 95, Cost 1.5990956860490704, Acc 0.696. Time 1.3454504013061523\n",
            "Training at Epoch 22/25, Batch 100, Cost 1.5823512243980646, Acc 0.722. Time 1.3450467586517334\n",
            "Training at Epoch 22/25, Batch 105, Cost 1.589805605036929, Acc 0.704. Time 1.3577008247375488\n",
            "Training at Epoch 22/25, Batch 110, Cost 1.575542193309786, Acc 0.744. Time 1.3305137157440186\n",
            "Training at Epoch 22/25, Batch 115, Cost 1.6124965440064976, Acc 0.708. Time 1.3598921298980713\n",
            "Training at Epoch 22/25, Batch 120, Cost 1.5858414591982137, Acc 0.72. Time 1.3449251651763916\n",
            "Testing at Epoch 22/25, Batch 5, Cost 1.6014415888337539, Acc 0.74. Time 0.33818626403808594\n",
            "Testing at Epoch 22/25, Batch 10, Cost 1.5723509312637671, Acc 0.738. Time 0.3426074981689453\n",
            "Testing at Epoch 22/25, Batch 15, Cost 1.5789306500917013, Acc 0.714. Time 0.33829736709594727\n",
            "Testing at Epoch 22/25, Batch 20, Cost 1.5743353476543118, Acc 0.742. Time 0.34029102325439453\n",
            "......\n",
            "Epoch 22/25, Train: Cost 1.599375242498896, Acc 0.7069500000000001\n",
            "Epoch 22/25, Test: Cost 1.5940987096033623, Acc 0.742. Time 181.41207027435303\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 23/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 23/25, Batch 5, Cost 1.6046357620501432, Acc 0.698. Time 1.3474409580230713\n",
            "Training at Epoch 23/25, Batch 10, Cost 1.6201781582856736, Acc 0.666. Time 1.3384475708007812\n",
            "Training at Epoch 23/25, Batch 15, Cost 1.5973022792113276, Acc 0.72. Time 1.352107048034668\n",
            "Training at Epoch 23/25, Batch 20, Cost 1.5919382948874208, Acc 0.694. Time 1.3389549255371094\n",
            "Training at Epoch 23/25, Batch 25, Cost 1.5958535999840249, Acc 0.692. Time 1.3379602432250977\n",
            "Training at Epoch 23/25, Batch 30, Cost 1.5846626464152085, Acc 0.726. Time 1.3470869064331055\n",
            "Training at Epoch 23/25, Batch 35, Cost 1.607087924475424, Acc 0.694. Time 1.3379271030426025\n",
            "Training at Epoch 23/25, Batch 40, Cost 1.598780705106967, Acc 0.724. Time 1.3394007682800293\n",
            "Training at Epoch 23/25, Batch 45, Cost 1.5939660652820593, Acc 0.7. Time 1.3387587070465088\n",
            "Training at Epoch 23/25, Batch 50, Cost 1.588674047275629, Acc 0.694. Time 1.3544790744781494\n",
            "Training at Epoch 23/25, Batch 55, Cost 1.6161930062570709, Acc 0.688. Time 1.3379266262054443\n",
            "Training at Epoch 23/25, Batch 60, Cost 1.6028987943820632, Acc 0.678. Time 1.357309103012085\n",
            "Training at Epoch 23/25, Batch 65, Cost 1.597065171574877, Acc 0.736. Time 1.3363330364227295\n",
            "Training at Epoch 23/25, Batch 70, Cost 1.5880609772193583, Acc 0.712. Time 1.3541243076324463\n",
            "Training at Epoch 23/25, Batch 75, Cost 1.5993852910005149, Acc 0.732. Time 1.3404855728149414\n",
            "Training at Epoch 23/25, Batch 80, Cost 1.6100649690655893, Acc 0.68. Time 1.3391988277435303\n",
            "Training at Epoch 23/25, Batch 85, Cost 1.6012573733372863, Acc 0.716. Time 1.3387572765350342\n",
            "Training at Epoch 23/25, Batch 90, Cost 1.588969403204403, Acc 0.742. Time 1.3379871845245361\n",
            "Training at Epoch 23/25, Batch 95, Cost 1.5812862172225444, Acc 0.734. Time 1.3484182357788086\n",
            "Training at Epoch 23/25, Batch 100, Cost 1.5981388184843202, Acc 0.698. Time 1.3355729579925537\n",
            "Training at Epoch 23/25, Batch 105, Cost 1.5970189169342586, Acc 0.724. Time 1.352466106414795\n",
            "Training at Epoch 23/25, Batch 110, Cost 1.5885404214976173, Acc 0.73. Time 1.337939977645874\n",
            "Training at Epoch 23/25, Batch 115, Cost 1.6031064968358344, Acc 0.7. Time 1.3347740173339844\n",
            "Training at Epoch 23/25, Batch 120, Cost 1.5982837304231585, Acc 0.7. Time 1.3356654644012451\n",
            "Testing at Epoch 23/25, Batch 5, Cost 1.5657625679776868, Acc 0.73. Time 0.3420898914337158\n",
            "Testing at Epoch 23/25, Batch 10, Cost 1.5810627144647884, Acc 0.714. Time 0.33759140968322754\n",
            "Testing at Epoch 23/25, Batch 15, Cost 1.58467015046359, Acc 0.724. Time 0.3398756980895996\n",
            "Testing at Epoch 23/25, Batch 20, Cost 1.600429468489621, Acc 0.676. Time 0.3390054702758789\n",
            "......\n",
            "Epoch 23/25, Train: Cost 1.598092087810946, Acc 0.7075\n",
            "Epoch 23/25, Test: Cost 1.5930223277732916, Acc 0.676. Time 180.6608805656433\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 24/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 24/25, Batch 5, Cost 1.5910689663860722, Acc 0.724. Time 1.356187343597412\n",
            "Training at Epoch 24/25, Batch 10, Cost 1.6127739481669594, Acc 0.692. Time 1.3449926376342773\n",
            "Training at Epoch 24/25, Batch 15, Cost 1.6023817218084002, Acc 0.692. Time 1.355031967163086\n",
            "Training at Epoch 24/25, Batch 20, Cost 1.5732975956905553, Acc 0.756. Time 1.3455767631530762\n",
            "Training at Epoch 24/25, Batch 25, Cost 1.6014935704717075, Acc 0.718. Time 1.3437628746032715\n",
            "Training at Epoch 24/25, Batch 30, Cost 1.5885358493794373, Acc 0.702. Time 1.3438115119934082\n",
            "Training at Epoch 24/25, Batch 35, Cost 1.593240341493651, Acc 0.702. Time 1.3441834449768066\n",
            "Training at Epoch 24/25, Batch 40, Cost 1.6002848446865243, Acc 0.706. Time 1.3523600101470947\n",
            "Training at Epoch 24/25, Batch 45, Cost 1.5930315989756465, Acc 0.736. Time 1.3467800617218018\n",
            "Training at Epoch 24/25, Batch 50, Cost 1.591194122025032, Acc 0.698. Time 1.3601031303405762\n",
            "Training at Epoch 24/25, Batch 55, Cost 1.604797730006413, Acc 0.686. Time 1.3431997299194336\n",
            "Training at Epoch 24/25, Batch 60, Cost 1.6006790632623424, Acc 0.714. Time 1.3466134071350098\n",
            "Training at Epoch 24/25, Batch 65, Cost 1.5898479902082172, Acc 0.728. Time 1.3434464931488037\n",
            "Training at Epoch 24/25, Batch 70, Cost 1.6176246715868379, Acc 0.674. Time 1.3594589233398438\n",
            "Training at Epoch 24/25, Batch 75, Cost 1.6018837903456564, Acc 0.73. Time 1.347433090209961\n",
            "Training at Epoch 24/25, Batch 80, Cost 1.5831247954013665, Acc 0.736. Time 1.343672752380371\n",
            "Training at Epoch 24/25, Batch 85, Cost 1.6000365476642042, Acc 0.704. Time 1.361539602279663\n",
            "Training at Epoch 24/25, Batch 90, Cost 1.5943230212829416, Acc 0.686. Time 1.334087610244751\n",
            "Training at Epoch 24/25, Batch 95, Cost 1.5843203888315793, Acc 0.694. Time 1.345679521560669\n",
            "Training at Epoch 24/25, Batch 100, Cost 1.592727149597521, Acc 0.73. Time 1.3312673568725586\n",
            "Training at Epoch 24/25, Batch 105, Cost 1.591232872828605, Acc 0.69. Time 1.3360345363616943\n",
            "Training at Epoch 24/25, Batch 110, Cost 1.612383397621871, Acc 0.732. Time 1.3355281352996826\n",
            "Training at Epoch 24/25, Batch 115, Cost 1.6092533432565865, Acc 0.75. Time 1.3328862190246582\n",
            "Training at Epoch 24/25, Batch 120, Cost 1.5855012418859045, Acc 0.714. Time 1.33486008644104\n",
            "Testing at Epoch 24/25, Batch 5, Cost 1.5835193922966566, Acc 0.742. Time 0.3388667106628418\n",
            "Testing at Epoch 24/25, Batch 10, Cost 1.5611899350732137, Acc 0.738. Time 0.3370625972747803\n",
            "Testing at Epoch 24/25, Batch 15, Cost 1.590891788463013, Acc 0.74. Time 0.33696508407592773\n",
            "Testing at Epoch 24/25, Batch 20, Cost 1.5891724408023953, Acc 0.708. Time 0.33727169036865234\n",
            "......\n",
            "Epoch 24/25, Train: Cost 1.597365361618678, Acc 0.70735\n",
            "Epoch 24/25, Test: Cost 1.5920775741539335, Acc 0.708. Time 181.11897802352905\n",
            "=-==-==-==-==-==-==-==-==-==-=\n",
            "Training at Epoch 25/25, Train batches 120, Test batches 20......\n",
            "Training at Epoch 25/25, Batch 5, Cost 1.5872760414978888, Acc 0.716. Time 1.3368935585021973\n",
            "Training at Epoch 25/25, Batch 10, Cost 1.5841658405587802, Acc 0.73. Time 1.3321008682250977\n",
            "Training at Epoch 25/25, Batch 15, Cost 1.6111507591954033, Acc 0.69. Time 1.3310625553131104\n",
            "Training at Epoch 25/25, Batch 20, Cost 1.6059254106680685, Acc 0.714. Time 1.336836338043213\n",
            "Training at Epoch 25/25, Batch 25, Cost 1.5856617278358842, Acc 0.71. Time 1.3412773609161377\n",
            "Training at Epoch 25/25, Batch 30, Cost 1.5942695246457548, Acc 0.71. Time 1.349273920059204\n",
            "Training at Epoch 25/25, Batch 35, Cost 1.619535105277662, Acc 0.662. Time 1.3403804302215576\n",
            "Training at Epoch 25/25, Batch 40, Cost 1.600496757113157, Acc 0.726. Time 1.3541183471679688\n",
            "Training at Epoch 25/25, Batch 45, Cost 1.5916852941619006, Acc 0.71. Time 1.3382453918457031\n",
            "Training at Epoch 25/25, Batch 50, Cost 1.604726920382317, Acc 0.724. Time 1.3442842960357666\n",
            "Training at Epoch 25/25, Batch 55, Cost 1.5817298056860793, Acc 0.728. Time 1.3400561809539795\n",
            "Training at Epoch 25/25, Batch 60, Cost 1.6040039658478877, Acc 0.694. Time 1.3405506610870361\n",
            "Training at Epoch 25/25, Batch 65, Cost 1.597242985423128, Acc 0.67. Time 1.3393819332122803\n",
            "Training at Epoch 25/25, Batch 70, Cost 1.5868204288183243, Acc 0.694. Time 1.3379745483398438\n",
            "Training at Epoch 25/25, Batch 75, Cost 1.58167758185202, Acc 0.702. Time 1.3503248691558838\n",
            "Training at Epoch 25/25, Batch 80, Cost 1.593911508859035, Acc 0.698. Time 1.341456413269043\n",
            "Training at Epoch 25/25, Batch 85, Cost 1.5973063479672884, Acc 0.688. Time 1.35115647315979\n",
            "Training at Epoch 25/25, Batch 90, Cost 1.59624905060277, Acc 0.718. Time 1.3357644081115723\n",
            "Training at Epoch 25/25, Batch 95, Cost 1.5829453410756213, Acc 0.716. Time 1.3366472721099854\n",
            "Training at Epoch 25/25, Batch 100, Cost 1.6033443696482865, Acc 0.724. Time 1.3386485576629639\n",
            "Training at Epoch 25/25, Batch 105, Cost 1.5959148493004203, Acc 0.734. Time 1.3384006023406982\n",
            "Training at Epoch 25/25, Batch 110, Cost 1.5784433159439577, Acc 0.712. Time 1.3517842292785645\n",
            "Training at Epoch 25/25, Batch 115, Cost 1.5996243371504395, Acc 0.714. Time 1.3387646675109863\n",
            "Training at Epoch 25/25, Batch 120, Cost 1.606178249093228, Acc 0.678. Time 1.3533813953399658\n",
            "Testing at Epoch 25/25, Batch 5, Cost 1.5748185972834676, Acc 0.702. Time 0.33643579483032227\n",
            "Testing at Epoch 25/25, Batch 10, Cost 1.5927409123714602, Acc 0.722. Time 0.3372464179992676\n",
            "Testing at Epoch 25/25, Batch 15, Cost 1.604906654585218, Acc 0.702. Time 0.3367733955383301\n",
            "Testing at Epoch 25/25, Batch 20, Cost 1.5855313954333803, Acc 0.712. Time 0.3367500305175781\n",
            "......\n",
            "Epoch 25/25, Train: Cost 1.5959815909378159, Acc 0.7075833333333333\n",
            "Epoch 25/25, Test: Cost 1.5910451142315236, Acc 0.712. Time 181.12651991844177\n",
            "=-==-==-==-==-==-==-==-==-==-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-cdab6e19e1eb>:14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  results_df = pd.concat(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# aggregate dataframe\n",
        "df_agg = results_df.groupby([\"n_train\", \"step\"]).agg([\"mean\", \"std\"])\n",
        "df_agg = df_agg.reset_index()\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "colors = sns.color_palette()\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(24, 7))\n",
        "\n",
        "generalization_errors = []\n",
        "\n",
        "# plot losses and accuracies\n",
        "for i, n_train in enumerate(train_sizes):\n",
        "    df = df_agg[df_agg.n_train == n_train]\n",
        "\n",
        "    dfs = [df.train_cost[\"mean\"], df.test_cost[\"mean\"], df.train_acc[\"mean\"], df.test_acc[\"mean\"]]\n",
        "    lines = [\"o-\", \"x--\", \"o-\", \"x--\"]\n",
        "    labels = [fr\"$N={n_train}$\", None, fr\"$N={n_train}$\", None]\n",
        "    axs = [0,0,1,1]\n",
        "\n",
        "    for k in range(4):\n",
        "        ax = axes[axs[k]]\n",
        "        ax.plot(df.step, dfs[k], lines[k], label=labels[k], markevery=10, color=colors[i], alpha=0.8)\n",
        "\n",
        "\n",
        "    # plot final loss difference\n",
        "    #dif = df[df.step == n_epochs].test_cost[\"mean\"] - df[df.step == n_epochs].train_cost[\"mean\"]\n",
        "    #generalization_errors.append(dif)\n",
        "\n",
        "# format loss plot\n",
        "ax = axes[0]\n",
        "ax.set_title('Train and Test Losses', fontsize=14)\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Loss')\n",
        "\n",
        "# format generalization error plot\n",
        "#ax = axes[1]\n",
        "#ax.plot(train_sizes, generalization_errors, \"o-\", label=r\"$gen(\\alpha)$\")\n",
        "#ax.set_xscale('log')\n",
        "#ax.set_xticks(train_sizes)\n",
        "#ax.set_xticklabels(train_sizes)\n",
        "#ax.set_title(r'Generalization Error $gen(\\alpha) = R(\\alpha) - \\hat{R}_N(\\alpha)$', fontsize=14)\n",
        "#ax.set_xlabel('Training Set Size')\n",
        "\n",
        "# format loss plot\n",
        "ax = axes[1]\n",
        "ax.set_title('Train and Test Accuracies', fontsize=14)\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_ylim(0.05, 1.05)\n",
        "\n",
        "legend_elements = [\n",
        "    mpl.lines.Line2D([0], [0], label=f'N={n}', color=colors[i]) for i, n in enumerate(train_sizes)\n",
        "    ] + [\n",
        "    mpl.lines.Line2D([0], [0], marker='o', ls='-', label='Train', color='Black'),\n",
        "    mpl.lines.Line2D([0], [0], marker='x', ls='--', label='Test', color='Black')\n",
        "    ]\n",
        "\n",
        "axes[0].legend(handles=legend_elements, ncol=3)\n",
        "axes[1].legend(handles=legend_elements, ncol=3)\n",
        "\n",
        "#axes[1].set_yscale('log', base=2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZZwqGAsnd4zT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "7aa101b2-815b-49f5-b565-8d61c386894a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2400x700 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "results_df.to_csv('random_results_60k_25epoch.csv', index=False)\n",
        "\n",
        "# Download the CSV file\n",
        "files.download('random_results_60k_25epoch.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gntxnXuednLQ",
        "outputId": "e676c648-8993-49c8-9335-dff2cd773f8e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fa578cbc-56a1-49cd-b2ac-b8a0fbefa768\", \"random_results_60k_25epoch.csv\", 1956)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "ZgX0UzIjd5lK",
        "outputId": "bea903fc-a68d-4e65-d734-76cda62deea3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    train_acc  train_cost  test_acc  test_cost step n_train\n",
              "0    0.607017    1.787945    0.6551   1.702593    1   60000\n",
              "1    0.671233    1.689990    0.6829   1.668684    2   60000\n",
              "2    0.681917    1.668003    0.6894   1.652335    3   60000\n",
              "3    0.688350    1.654345    0.6929   1.647127    4   60000\n",
              "4    0.692633    1.645591    0.6982   1.636612    5   60000\n",
              "5    0.695750    1.639051    0.7044   1.626210    6   60000\n",
              "6    0.696817    1.632906    0.7012   1.626262    7   60000\n",
              "7    0.698683    1.628545    0.7022   1.621418    8   60000\n",
              "8    0.699517    1.623991    0.7014   1.618681    9   60000\n",
              "9    0.700483    1.620978    0.7039   1.614420   10   60000\n",
              "10   0.702250    1.618653    0.7027   1.613833   11   60000\n",
              "11   0.702717    1.615398    0.7072   1.608892   12   60000\n",
              "12   0.703450    1.613052    0.7072   1.608331   13   60000\n",
              "13   0.703850    1.610924    0.7075   1.604422   14   60000\n",
              "14   0.704133    1.609883    0.7084   1.603917   15   60000\n",
              "15   0.705067    1.607323    0.7088   1.601463   16   60000\n",
              "16   0.705367    1.605282    0.7096   1.599743   17   60000\n",
              "17   0.705633    1.604513    0.7085   1.599641   18   60000\n",
              "18   0.706450    1.603325    0.7094   1.597673   19   60000\n",
              "19   0.706267    1.601681    0.7108   1.595807   20   60000\n",
              "20   0.706700    1.600350    0.7110   1.593411   21   60000\n",
              "21   0.706950    1.599375    0.7097   1.594099   22   60000\n",
              "22   0.707500    1.598092    0.7116   1.593022   23   60000\n",
              "23   0.707350    1.597365    0.7112   1.592078   24   60000\n",
              "24   0.707583    1.595982    0.7102   1.591045   25   60000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-deb0b8c2-7e9e-490c-994d-e1236400db81\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train_acc</th>\n",
              "      <th>train_cost</th>\n",
              "      <th>test_acc</th>\n",
              "      <th>test_cost</th>\n",
              "      <th>step</th>\n",
              "      <th>n_train</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.607017</td>\n",
              "      <td>1.787945</td>\n",
              "      <td>0.6551</td>\n",
              "      <td>1.702593</td>\n",
              "      <td>1</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.671233</td>\n",
              "      <td>1.689990</td>\n",
              "      <td>0.6829</td>\n",
              "      <td>1.668684</td>\n",
              "      <td>2</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.681917</td>\n",
              "      <td>1.668003</td>\n",
              "      <td>0.6894</td>\n",
              "      <td>1.652335</td>\n",
              "      <td>3</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.688350</td>\n",
              "      <td>1.654345</td>\n",
              "      <td>0.6929</td>\n",
              "      <td>1.647127</td>\n",
              "      <td>4</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.692633</td>\n",
              "      <td>1.645591</td>\n",
              "      <td>0.6982</td>\n",
              "      <td>1.636612</td>\n",
              "      <td>5</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.695750</td>\n",
              "      <td>1.639051</td>\n",
              "      <td>0.7044</td>\n",
              "      <td>1.626210</td>\n",
              "      <td>6</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.696817</td>\n",
              "      <td>1.632906</td>\n",
              "      <td>0.7012</td>\n",
              "      <td>1.626262</td>\n",
              "      <td>7</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.698683</td>\n",
              "      <td>1.628545</td>\n",
              "      <td>0.7022</td>\n",
              "      <td>1.621418</td>\n",
              "      <td>8</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.699517</td>\n",
              "      <td>1.623991</td>\n",
              "      <td>0.7014</td>\n",
              "      <td>1.618681</td>\n",
              "      <td>9</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.700483</td>\n",
              "      <td>1.620978</td>\n",
              "      <td>0.7039</td>\n",
              "      <td>1.614420</td>\n",
              "      <td>10</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.702250</td>\n",
              "      <td>1.618653</td>\n",
              "      <td>0.7027</td>\n",
              "      <td>1.613833</td>\n",
              "      <td>11</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.702717</td>\n",
              "      <td>1.615398</td>\n",
              "      <td>0.7072</td>\n",
              "      <td>1.608892</td>\n",
              "      <td>12</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.703450</td>\n",
              "      <td>1.613052</td>\n",
              "      <td>0.7072</td>\n",
              "      <td>1.608331</td>\n",
              "      <td>13</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.703850</td>\n",
              "      <td>1.610924</td>\n",
              "      <td>0.7075</td>\n",
              "      <td>1.604422</td>\n",
              "      <td>14</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.704133</td>\n",
              "      <td>1.609883</td>\n",
              "      <td>0.7084</td>\n",
              "      <td>1.603917</td>\n",
              "      <td>15</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.705067</td>\n",
              "      <td>1.607323</td>\n",
              "      <td>0.7088</td>\n",
              "      <td>1.601463</td>\n",
              "      <td>16</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.705367</td>\n",
              "      <td>1.605282</td>\n",
              "      <td>0.7096</td>\n",
              "      <td>1.599743</td>\n",
              "      <td>17</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.705633</td>\n",
              "      <td>1.604513</td>\n",
              "      <td>0.7085</td>\n",
              "      <td>1.599641</td>\n",
              "      <td>18</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.706450</td>\n",
              "      <td>1.603325</td>\n",
              "      <td>0.7094</td>\n",
              "      <td>1.597673</td>\n",
              "      <td>19</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.706267</td>\n",
              "      <td>1.601681</td>\n",
              "      <td>0.7108</td>\n",
              "      <td>1.595807</td>\n",
              "      <td>20</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.706700</td>\n",
              "      <td>1.600350</td>\n",
              "      <td>0.7110</td>\n",
              "      <td>1.593411</td>\n",
              "      <td>21</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.706950</td>\n",
              "      <td>1.599375</td>\n",
              "      <td>0.7097</td>\n",
              "      <td>1.594099</td>\n",
              "      <td>22</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.707500</td>\n",
              "      <td>1.598092</td>\n",
              "      <td>0.7116</td>\n",
              "      <td>1.593022</td>\n",
              "      <td>23</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.707350</td>\n",
              "      <td>1.597365</td>\n",
              "      <td>0.7112</td>\n",
              "      <td>1.592078</td>\n",
              "      <td>24</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.707583</td>\n",
              "      <td>1.595982</td>\n",
              "      <td>0.7102</td>\n",
              "      <td>1.591045</td>\n",
              "      <td>25</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-deb0b8c2-7e9e-490c-994d-e1236400db81')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-deb0b8c2-7e9e-490c-994d-e1236400db81 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-deb0b8c2-7e9e-490c-994d-e1236400db81');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4656d55c-479e-48c1-b9b4-dbb1d547c959\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4656d55c-479e-48c1-b9b4-dbb1d547c959')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4656d55c-479e-48c1-b9b4-dbb1d547c959 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c9b12b64-e253-488c-af37-007f9b8fc387\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c9b12b64-e253-488c-af37-007f9b8fc387 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"train_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.020622582911117755,\n        \"min\": 0.6070166666666666,\n        \"max\": 0.7075833333333333,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          0.6995166666666667,\n          0.7053666666666667,\n          0.6070166666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_cost\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04109893997664963,\n        \"min\": 1.5959815909378159,\n        \"max\": 1.787944982106262,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          1.62399111963947,\n          1.6052820810550656,\n          1.787944982106262\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012264300496427282,\n        \"min\": 0.6551,\n        \"max\": 0.7116,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          0.7014,\n          0.7085,\n          0.6551\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_cost\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.027252602695430655,\n        \"min\": 1.5910451142315236,\n        \"max\": 1.70259297994475,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          1.618681292259928,\n          1.5997434578260101,\n          1.70259297994475\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"step\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 1,\n        \"max\": 25,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          9,\n          17,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_train\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 60000,\n        \"max\": 60000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          60000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_folder = \"/content/drive/MyDrive/Research/HermtianEncodingImg/mnist\"\n",
        "results_df.to_csv(os.path.join(save_folder, \"mnist_HermImgReUpload_results.csv\"))\n",
        "df_agg.to_csv(os.path.join(save_folder, \"mnist_HermImgReUpload_results_agg.csv\"))\n",
        "# save the plot to file\n",
        "fig.savefig(os.path.join(save_folder, \"mnist_HermImgReUpload_results.png\"))"
      ],
      "metadata": {
        "id": "wr-ZnyKwd5dm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "26cc930e-9fc3-4503-f497-c7c01c28e61d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Cannot save file into a non-existent directory: '/content/drive/MyDrive/Research/HermtianEncodingImg/mnist'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ec7e5d0efec0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msave_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Research/HermtianEncodingImg/mnist\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mnist_HermImgReUpload_results.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_agg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mnist_HermImgReUpload_results_agg.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# save the plot to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mnist_HermImgReUpload_results.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 )\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3965\u001b[0m         )\n\u001b[1;32m   3966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3967\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3968\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         )\n\u001b[0;32m-> 1014\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \"\"\"\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/content/drive/MyDrive/Research/HermtianEncodingImg/mnist'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kukubDx5CD26"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}